{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13952689,"sourceType":"datasetVersion","datasetId":8893341},{"sourceId":13970573,"sourceType":"datasetVersion","datasetId":8906347}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"f71fe92e","cell_type":"markdown","source":"## üìã Setup & Installation","metadata":{}},{"id":"f984caaf","cell_type":"code","source":"%%capture\nimport os, re\nif \"COLAB_\" not in \"\".join(os.environ.keys()):\n    !pip install unsloth\nelse:\n    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n    import torch; v = re.match(r\"[0-9]{1,}\\.[0-9]{1,}\", str(torch.__version__)).group(0)\n    xformers = \"xformers==\" + (\"0.0.33.post1\" if v==\"2.9\" else \"0.0.32.post2\" if v==\"2.8\" else \"0.0.29.post3\")\n    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n    !pip install sentencepiece protobuf \"datasets==4.3.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n    !pip install --no-deps unsloth\n!pip install transformers==4.56.2\n!pip install --no-deps trl==0.22.2\n!pip install wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T12:11:33.197234Z","iopub.execute_input":"2025-12-03T12:11:33.197872Z","iopub.status.idle":"2025-12-03T12:12:11.798457Z","shell.execute_reply.started":"2025-12-03T12:11:33.197834Z","shell.execute_reply":"2025-12-03T12:12:11.797488Z"}},"outputs":[],"execution_count":1},{"id":"0c48c422","cell_type":"code","source":"import os\nimport json\nimport torch\nimport wandb\nfrom datasets import Dataset, load_dataset\nfrom unsloth import FastLanguageModel\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport gc\n\n# Check GPU\nprint(f\"GPU Available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T12:12:11.799974Z","iopub.execute_input":"2025-12-03T12:12:11.800539Z","iopub.status.idle":"2025-12-03T12:12:51.786347Z","shell.execute_reply.started":"2025-12-03T12:12:11.800514Z","shell.execute_reply":"2025-12-03T12:12:51.785497Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-12-03 12:12:20.467076: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764763940.655734      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764763940.708338      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"ü¶• Unsloth Zoo will now patch everything to make training faster!\nGPU Available: True\nGPU Name: Tesla T4\nGPU Memory: 15.83 GB\n","output_type":"stream"}],"execution_count":2},{"id":"8d854241","cell_type":"markdown","source":"## üîê WandB Login (for monitoring)","metadata":{}},{"id":"4aae7ae2","cell_type":"code","source":"# Login to WandB for experiment tracking\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_api_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n\n# Login with API key from Kaggle Secrets\nwandb.login(key=wandb_api_key)\n\n\n# Initialize WandB project with GRPO synthetic data config\nwandb.init(\n    project=\"vietnamese-legal-ai-sft-v2\",\n    name=\"llama3.2-3b-grpo-synthetic-sft-v1\",\n    config={\n        \"base_model\": \"mikeethanh/vietnamese-legal-llama3.2-3b-merged-grpo\",\n        \"dataset\": \"synthetic_legal_qa_grpo_training.jsonl\",\n        \"task\": \"structured_legal_qa\",\n        \"language\": \"vietnamese\",\n        \"format\": \"grpo_structured\",\n        \"max_seq_length\": 2048,  # Increased for structured format\n        \"lora_r\": 16,  # Reduced since base model already fine-tuned\n        \"lora_alpha\": 16,\n        \"learning_rate\": 1e-4,  # Lower LR for already fine-tuned model\n        \"num_epochs\": 1,  # Less epochs needed\n        \"batch_size\": 2,\n        \"gradient_accumulation\": 8,\n        \"effective_batch_size\": 16,\n    },\n    settings=wandb.Settings(\n        _disable_meta=False,\n        _disable_stats=False,\n    )\n)\n\nprint(\"‚úÖ WandB initialized for GRPO synthetic data training\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T12:12:51.787230Z","iopub.execute_input":"2025-12-03T12:12:51.787968Z","iopub.status.idle":"2025-12-03T12:13:06.342416Z","shell.execute_reply.started":"2025-12-03T12:12:51.787947Z","shell.execute_reply":"2025-12-03T12:13:06.341627Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmikeethanh04\u001b[0m (\u001b[33mmikeethanh04-student\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251203_121259-lmlfz4fx</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-sft-v2/runs/lmlfz4fx' target=\"_blank\">llama3.2-3b-grpo-synthetic-sft-v1</a></strong> to <a href='https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-sft-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-sft-v2' target=\"_blank\">https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-sft-v2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-sft-v2/runs/lmlfz4fx' target=\"_blank\">https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-sft-v2/runs/lmlfz4fx</a>"},"metadata":{}},{"name":"stdout","text":"‚úÖ WandB initialized for GRPO synthetic data training\n","output_type":"stream"}],"execution_count":3},{"id":"1914eb73","cell_type":"markdown","source":"## ‚öôÔ∏è Model Configuration - GRPO Merged Model\n\n### T·∫°i sao s·ª≠ d·ª•ng GRPO merged model?\n- ‚úÖ **Already GRPO trained**: Model ƒë√£ ƒë∆∞·ª£c train v·ªõi GRPO format\n- ‚úÖ **Structured reasoning**: ƒê√£ bi·∫øt format `<start_working_out>` v√† `<SOLUTION>`\n- ‚úÖ **Domain adapted**: ƒê√£ fine-tune tr√™n legal domain\n- ‚úÖ **Consistent format**: S·∫Ω d·ªÖ d√†ng h·ªçc synthetic data c√πng format\n- ‚úÖ **Less training needed**: Ch·ªâ c·∫ßn √≠t epochs ƒë·ªÉ adapt v·ªõi synthetic data","metadata":{}},{"id":"cb2b08f8","cell_type":"code","source":"# Model configuration for GRPO merged model\nmax_seq_length = 2048  # Increased for structured format with reasoning\ndtype = None  # Auto-detect. Use Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True  # Use 4bit quantization to reduce memory usage\n\n# Load the GRPO merged model\nmodel_name = \"mikeethanh/vietnamese-legal-llama3.2-3b-merged-grpo-v1\"  # Your GRPO merged model\n\nprint(f\"üîÑ Loading GRPO merged model: {model_name}\")\nprint(\"‚ö†Ô∏è This model already contains GRPO training adaptations\")\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=model_name,\n    max_seq_length=max_seq_length,\n    dtype=dtype,\n    load_in_4bit=load_in_4bit,\n)\n\nprint(f\"‚úÖ GRPO merged model loaded: {model_name}\")\nprint(f\"üìè Max sequence length: {max_seq_length}\")\nprint(f\"üî¢ 4-bit quantization: {load_in_4bit}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T12:13:06.343207Z","iopub.execute_input":"2025-12-03T12:13:06.343431Z","iopub.status.idle":"2025-12-03T12:14:29.468163Z","shell.execute_reply.started":"2025-12-03T12:13:06.343408Z","shell.execute_reply":"2025-12-03T12:14:29.467125Z"}},"outputs":[{"name":"stdout","text":"üîÑ Loading GRPO merged model: mikeethanh/vietnamese-legal-llama3.2-3b-merged-grpo-v1\n‚ö†Ô∏è This model already contains GRPO training adaptations\n==((====))==  Unsloth 2025.11.6: Fast Llama patching. Transformers: 4.56.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cde5e9595c1c4f68808f29d836edbb62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b773ece19d0f487b8374056560628999"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f4697f013784b2481eaacc17bba9c68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40510a90e1c94e95bde058c86793fe80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8423978d2eb7443ab0fd283ca6b14bba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"678f63c17c834f65a60812b34a4d84db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eaf954e959849dba3bb8c48c906af48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8894aa3059fd42a4830e3882b6cb8f79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.jinja:   0%|          | 0.00/943 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"113af100c6d249a2a4afd46b7df2f6dd"}},"metadata":{}},{"name":"stdout","text":"‚úÖ GRPO merged model loaded: mikeethanh/vietnamese-legal-llama3.2-3b-merged-grpo-v1\nüìè Max sequence length: 2048\nüî¢ 4-bit quantization: True\n","output_type":"stream"}],"execution_count":4},{"id":"202967d3","cell_type":"markdown","source":"## üéØ LoRA Configuration - Lighter for Already Fine-tuned Model\n\n","metadata":{}},{"id":"55cdfd49","cell_type":"code","source":"# Apply LoRA adapters v·ªõi settings nh·∫π h∆°n cho model ƒë√£ fine-tune\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r=32,  # Reduced from 32 since model is already fine-tuned\n    target_modules=[\n        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n        \"gate_proj\", \"up_proj\", \"down_proj\",\n    ],  # All attention & MLP layers\n    lora_alpha=32,  # Equal to r\n    lora_dropout=0,  # 0 is optimized by Unsloth\n    bias=\"none\",  # \"none\" is optimized\n    use_gradient_checkpointing=\"unsloth\",  # Unsloth's long context support\n    random_state=3407,  # For reproducibility\n    use_rslora=False,  # Rank stabilized LoRA\n    loftq_config=None,  # LoftQ quantization\n)\n\nprint(\"‚úÖ LoRA adapters applied (lighter config for pre-trained model)\")\nprint(f\"üìä Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\nprint(f\"üìä Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\nprint(f\"üí° Trainable ratio: {100 * sum(p.numel() for p in model.parameters() if p.requires_grad) / sum(p.numel() for p in model.parameters()):.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T12:14:29.469965Z","iopub.execute_input":"2025-12-03T12:14:29.470191Z","iopub.status.idle":"2025-12-03T12:14:36.706983Z","shell.execute_reply.started":"2025-12-03T12:14:29.470174Z","shell.execute_reply":"2025-12-03T12:14:36.706148Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.11.6 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ LoRA adapters applied (lighter config for pre-trained model)\nüìä Trainable parameters: 48,627,712\nüìä Total parameters: 1,852,091,392\nüí° Trainable ratio: 2.63%\n","output_type":"stream"}],"execution_count":5},{"id":"f09db0d2","cell_type":"markdown","source":"## üìä GRPO Synthetic Data Preparation\n\n### Expected Data Format:\n```json\n{\n  \"messages\": [\n    {\"role\": \"system\", \"content\": \"System prompt v·ªõi GRPO format\"},\n    {\"role\": \"user\", \"content\": \"C√¢u h·ªèi ph√°p lu·∫≠t\"},\n    {\"role\": \"assistant\", \"content\": \"<start_working_out>\\nSuy nghƒ©...\\n<end_working_out>\\n\\n<SOLUTION>C√¢u tr·∫£ l·ªùi</SOLUTION>\"}\n  ]\n}\n```","metadata":{}},{"id":"d475ba63","cell_type":"code","source":"# Load GRPO synthetic data\n# Update path to your synthetic data file\ndata_path = \"/kaggle/input/synthetic-legal/synthetic_legal_qa_grpo_format_3k.jsonl\"  # Correct path\n\nprint(f\"üîç Looking for GRPO synthetic data at: {data_path}\")\n\n# Check if file exists\nif not os.path.exists(data_path):\n    print(f\"‚ö†Ô∏è Data file not found at {data_path}\")\n    print(\"üì• Please check the path or upload the file\")\n    \n    # Alternative: Try different common paths\n    alternative_paths = [\n        \"/content/synthetic_legal_qa_grpo_format.jsonl\",  # Colab\n        \"/kaggle/input/grpo-synthetic-data/synthetic_legal_qa_grpo_format.jsonl\",  # Kaggle\n        \"synthetic_legal_qa_grpo_format.jsonl\",  # Current directory\n    ]\n    \n    for alt_path in alternative_paths:\n        if os.path.exists(alt_path):\n            data_path = alt_path\n            print(f\"‚úÖ Found data at alternative path: {data_path}\")\n            break\n    else:\n        print(\"‚ùå Please ensure the GRPO synthetic data file is available\")\n        raise FileNotFoundError(f\"Data file not found: {data_path}\")\n\n# Load JSONL data and convert to messages format\ndata = []\nwith open(data_path, 'r', encoding='utf-8') as f:\n    for line in f:\n        item = json.loads(line)\n        # Convert from question/answer format to messages format\n        messages_item = {\n            \"messages\": [\n                {\n                    \"role\": \"system\", \n                    \"content\": \"B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n v·ªÅ lu·∫≠t giao th√¥ng Vi·ªát Nam. Khi tr·∫£ l·ªùi c√¢u h·ªèi, h√£y: 1. Suy nghƒ© v√† ph√¢n t√≠ch c√¢u h·ªèi trong ph·∫ßn <start_working_out> <end_working_out> 2. ƒê∆∞a ra c√¢u tr·∫£ l·ªùi ch√≠nh x√°c trong ph·∫ßn <SOLUTION></SOLUTION>\"\n                },\n                {\n                    \"role\": \"user\", \n                    \"content\": item[\"question\"]\n                },\n                {\n                    \"role\": \"assistant\", \n                    \"content\": item[\"answer\"]\n                }\n            ]\n        }\n        data.append(messages_item)\n\nprint(f\"\\nüìä Loaded {len(data):,} GRPO training samples\")\nprint(f\"üìä Converted from question/answer format to messages format\")\n\n# Show sample\nprint(\"\\nüìù Sample GRPO data structure:\")\nsample = data[0]\nprint(f\"Keys: {list(sample.keys())}\")\nif \"messages\" in sample:\n    print(f\"\\nMessages structure:\")\n    for i, msg in enumerate(sample[\"messages\"]):\n        content_preview = msg[\"content\"][:100] + \"...\" if len(msg[\"content\"]) > 100 else msg[\"content\"]\n        print(f\"  {i+1}. {msg['role']}: {content_preview}\")\n        \n# Validate GRPO format\ngrpo_format_count = 0\nfor item in data[:100]:  # Check first 100 samples\n    if \"messages\" in item:\n        for msg in item[\"messages\"]:\n            if msg[\"role\"] == \"assistant\":\n                if \"<start_working_out>\" in msg[\"content\"] and \"<SOLUTION>\" in msg[\"content\"]:\n                    grpo_format_count += 1\n                break\n\nprint(f\"\\n‚úÖ GRPO format validation: {grpo_format_count}/100 samples have proper structure\")\nif grpo_format_count >= 50:\n    print(\"üéâ Excellent! Data has good GRPO format compliance\")\nelse:\n    print(\"‚ö†Ô∏è Warning: Low GRPO format compliance. Check data generation.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T12:14:36.707903Z","iopub.execute_input":"2025-12-03T12:14:36.708188Z","iopub.status.idle":"2025-12-03T12:14:36.844528Z","shell.execute_reply.started":"2025-12-03T12:14:36.708164Z","shell.execute_reply":"2025-12-03T12:14:36.843778Z"}},"outputs":[{"name":"stdout","text":"üîç Looking for GRPO synthetic data at: /kaggle/input/synthetic-legal/synthetic_legal_qa_grpo_format_3k.jsonl\n\nüìä Loaded 1,795 GRPO training samples\nüìä Converted from question/answer format to messages format\n\nüìù Sample GRPO data structure:\nKeys: ['messages']\n\nMessages structure:\n  1. system: B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n v·ªÅ lu·∫≠t giao th√¥ng Vi·ªát Nam. Khi tr·∫£ l·ªùi c√¢u h·ªèi, h√£y: 1. Suy nghƒ© v√† ph...\n  2. user: Ph·∫°m vi ƒëi·ªÅu ch·ªânh c·ªßa Lu·∫≠t ƒê∆∞·ªùng b·ªô c√≥ √Ω nghƒ©a nh∆∞ th·∫ø n√†o ƒë·ªëi v·ªõi c√°c ho·∫°t ƒë·ªông giao th√¥ng ƒë∆∞·ªùng b...\n  3. assistant: <start_working_out>\nƒê·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y m·ªôt c√°ch to√†n di·ªán, t√¥i c·∫ßn ph√¢n t√≠ch chi ti·∫øt vƒÉn b·∫£n ph...\n\n‚úÖ GRPO format validation: 100/100 samples have proper structure\nüéâ Excellent! Data has good GRPO format compliance\n","output_type":"stream"}],"execution_count":6},{"id":"d8359083","cell_type":"code","source":"# Split data: 85% train, 10% validation, 5% test (less aggressive split for synthetic data)\ntrain_data, temp_data = train_test_split(data, test_size=0.15, random_state=42)\nval_data, test_data = train_test_split(temp_data, test_size=0.33, random_state=42)  # 5% test, 10% val\n\nprint(f\"üìä Train: {len(train_data):,} samples ({len(train_data)/len(data)*100:.1f}%)\")\nprint(f\"üìä Validation: {len(val_data):,} samples ({len(val_data)/len(data)*100:.1f}%)\")\nprint(f\"üìä Test: {len(test_data):,} samples ({len(test_data)/len(data)*100:.1f}%)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T12:14:36.845621Z","iopub.execute_input":"2025-12-03T12:14:36.845916Z","iopub.status.idle":"2025-12-03T12:14:36.854756Z","shell.execute_reply.started":"2025-12-03T12:14:36.845891Z","shell.execute_reply":"2025-12-03T12:14:36.854020Z"}},"outputs":[{"name":"stdout","text":"üìä Train: 1,525 samples (85.0%)\nüìä Validation: 180 samples (10.0%)\nüìä Test: 90 samples (5.0%)\n","output_type":"stream"}],"execution_count":7},{"id":"c48f0387","cell_type":"markdown","source":"## üìù Chat Template cho GRPO Format\n\nData ƒë√£ c√≥ format messages, ch·ªâ c·∫ßn convert sang text format cho training:","metadata":{}},{"id":"70ff2513","cell_type":"code","source":"# Convert to HuggingFace Dataset and format for Unsloth\nprint(\"üîÑ Converting data to HuggingFace Dataset format...\")\n\ndef format_chat_for_unsloth(examples):\n    \"\"\"Format chat data for Unsloth training\"\"\"\n    texts = []\n    \n    # Handle batch processing\n    if isinstance(examples, dict) and \"messages\" in examples:\n        # Single example\n        examples = [examples]\n    elif isinstance(examples, dict) and isinstance(examples.get(\"messages\", []), list) and len(examples[\"messages\"]) > 0 and isinstance(examples[\"messages\"][0], list):\n        # Batch of examples where examples[\"messages\"] is a list of message lists\n        examples = [{\"messages\": msg_list} for msg_list in examples[\"messages\"]]\n    elif isinstance(examples, list):\n        # Already a list of examples\n        pass\n    else:\n        # Convert from dataset format\n        if \"messages\" in examples and isinstance(examples[\"messages\"], list):\n            if len(examples[\"messages\"]) > 0 and isinstance(examples[\"messages\"][0], list):\n                # Batch format: examples[\"messages\"] = [msg_list1, msg_list2, ...]\n                examples = [{\"messages\": msg_list} for msg_list in examples[\"messages\"]]\n            else:\n                # Single example wrapped in batch\n                examples = [examples]\n    \n    for example in examples:\n        messages = example[\"messages\"]\n        \n        # Extract parts from messages\n        system_msg = \"\"\n        user_msg = \"\"\n        assistant_msg = \"\"\n        \n        for msg in messages:\n            if msg[\"role\"] == \"system\":\n                system_msg = msg[\"content\"]\n            elif msg[\"role\"] == \"user\":\n                user_msg = msg[\"content\"]\n            elif msg[\"role\"] == \"assistant\":\n                assistant_msg = msg[\"content\"]\n        \n        # Format for Unsloth training (ChatML-like format)\n        conversation = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\n{system_msg}<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n{user_msg}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n{assistant_msg}<|eot_id|>\"\"\"\n        \n        texts.append(conversation)\n    \n    return {\"text\": texts}\n\n# Convert to HuggingFace Dataset\ntrain_dataset = Dataset.from_list(train_data)\nval_dataset = Dataset.from_list(val_data)\ntest_dataset = Dataset.from_list(test_data)\n\nprint(\"‚úÖ Datasets created successfully\")\nprint(f\"üìä Train dataset: {len(train_dataset)} samples\")\nprint(f\"üìä Validation dataset: {len(val_dataset)} samples\") \nprint(f\"üìä Test dataset: {len(test_dataset)} samples\")\n\n# Format for Unsloth training\nprint(\"üîÑ Formatting data for Unsloth training...\")\n\ntrain_dataset = train_dataset.map(\n    format_chat_for_unsloth, \n    batched=True,\n    remove_columns=train_dataset.column_names\n)\n\nval_dataset = val_dataset.map(\n    format_chat_for_unsloth, \n    batched=True,\n    remove_columns=val_dataset.column_names\n)\n\nprint(\"‚úÖ Data formatted for Unsloth training\")\nprint(\"\\nüìù Example formatted conversation:\")\nprint(train_dataset[0]['text'][:800] + \"...\")\n\n# Show token statistics\nprint(\"\\nüìä Dataset Statistics:\")\nprint(f\"üìè Train samples: {len(train_dataset)}\")\nprint(f\"üìè Val samples: {len(val_dataset)}\")\nif len(train_dataset) > 0:\n    sample_text = train_dataset[0]['text']\n    sample_tokens = len(tokenizer.encode(sample_text))\n    print(f\"üìè Sample text length: {sample_tokens} tokens\")\n    print(f\"üìè Estimated max tokens needed: {sample_tokens}\")\n\n    # Check if sequence is too long\n    if sample_tokens > max_seq_length:\n        print(f\"‚ö†Ô∏è Warning: Sample length ({sample_tokens}) exceeds max_seq_length ({max_seq_length})\")\n        print(\"üí° Consider increasing max_seq_length or truncating data\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T12:14:36.855601Z","iopub.execute_input":"2025-12-03T12:14:36.855898Z","iopub.status.idle":"2025-12-03T12:14:37.122832Z","shell.execute_reply.started":"2025-12-03T12:14:36.855864Z","shell.execute_reply":"2025-12-03T12:14:37.122061Z"}},"outputs":[{"name":"stdout","text":"üîÑ Converting data to HuggingFace Dataset format...\n‚úÖ Datasets created successfully\nüìä Train dataset: 1525 samples\nüìä Validation dataset: 180 samples\nüìä Test dataset: 90 samples\nüîÑ Formatting data for Unsloth training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1525 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68a534bdafcb4a928a36570f24a1b523"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/180 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa1a16c4af2e48f19c16dbd99b984b81"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Data formatted for Unsloth training\n\nüìù Example formatted conversation:\n<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nB·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n v·ªÅ lu·∫≠t giao th√¥ng Vi·ªát Nam. Khi tr·∫£ l·ªùi c√¢u h·ªèi, h√£y: 1. Suy nghƒ© v√† ph√¢n t√≠ch c√¢u h·ªèi trong ph·∫ßn <start_working_out> <end_working_out> 2. ƒê∆∞a ra c√¢u tr·∫£ l·ªùi ch√≠nh x√°c trong ph·∫ßn <SOLUTION></SOLUTION><|eot_id|><|start_header_id|>user<|end_header_id|>\n\nN·∫øu m·ªôt b√£i ƒë·ªó xe b·ªã ph√°t hi·ªán vi ph·∫°m quy ƒë·ªãnh v·ªÅ gi·ªØ g√¨n v·ªá sinh m√¥i tr∆∞·ªùng, c√°c b∆∞·ªõc x·ª≠ l√Ω c·ª• th·ªÉ s·∫Ω l√† g√¨?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n<start_working_out>\nC√¢u h·ªèi ƒë·∫∑t ra li√™n quan ƒë·∫øn vi·ªác x·ª≠ l√Ω vi ph·∫°m quy ƒë·ªãnh v·ªÅ gi·ªØ g√¨n v·ªá sinh m√¥i tr∆∞·ªùng t·∫°i c√°c b√£i ƒë·ªó xe ·ªü Vi·ªát Nam. Ng∆∞·ªùi d√πng mu·ªën bi·∫øt r√µ c√°c b∆∞·ªõc x·ª≠ l√Ω khi m·ªôt b√£i ƒë·ªó xe kh√¥ng th·ª±c hi·ªán ƒë√∫ng nghƒ©a v·ª• b·∫£o ƒë·∫£m v·ªá sinh m√¥i tr∆∞·ªùng, v√† ƒëi·ªÅu n√†y c√≥ th·ªÉ bao g·ªìm c·∫£ c√°c h√¨nh ...\n\nüìä Dataset Statistics:\nüìè Train samples: 1525\nüìè Val samples: 180\nüìè Sample text length: 986 tokens\nüìè Estimated max tokens needed: 986\n","output_type":"stream"}],"execution_count":8},{"id":"5001bd9b","cell_type":"markdown","source":"## üéì Training Configuration - Optimized for GRPO Synthetic Data\n\n### Settings cho model ƒë√£ fine-tune + synthetic data:\n- **Epochs**: 1-2 (model ƒë√£ c√≥ base knowledge)\n- **Learning rate**: 5e-5 ƒë·∫øn 1e-4 (th·∫•p h∆°n)\n- **Batch size**: Nh·ªè h∆°n do sequence d√†i h∆°n\n- **More evaluation**: Monitor overfitting carefully","metadata":{}},{"id":"a49be28c","cell_type":"code","source":"# Training arguments optimized for GRPO synthetic data\ntraining_args = TrainingArguments(\n    # Output & Logging\n    output_dir=\"./outputs-grpo-synthetic\",\n    run_name=\"llama3.2-3b-grpo-synthetic-v1\",\n    \n    # Training dynamics - Conservative for already fine-tuned model\n    num_train_epochs=5,  # Start with 1 epoch, can increase if needed\n    per_device_train_batch_size=4,  # Reduced due to longer sequences\n    gradient_accumulation_steps=4,  # Increased to maintain effective batch size = 16\n    \n    # Optimization - Lower LR for already fine-tuned model\n    optim=\"adamw_8bit\",  # 8-bit AdamW for memory efficiency\n    learning_rate=3e-4,  # Lower LR than fresh model (was 2e-4)\n    weight_decay=0.01,\n    warmup_ratio=0.05,  # Shorter warmup (5% instead of 10%)\n    lr_scheduler_type=\"cosine\",  # Cosine annealing\n    \n    # Performance\n    fp16=not torch.cuda.is_bf16_supported(),  # Use FP16 for T4\n    bf16=torch.cuda.is_bf16_supported(),  # Use BF16 if supported\n    \n    # Logging & Saving - More frequent for careful monitoring\n    logging_steps=2,  # Very frequent logging for synthetic data\n    logging_strategy=\"steps\",\n    logging_first_step=True,\n    save_strategy=\"steps\",\n    save_steps=25,  # Save very frequently to avoid overfitting\n    save_total_limit=3,\n    \n    # Evaluation - Very frequent to catch overfitting early\n    eval_strategy=\"steps\",\n    eval_steps=25,  # Frequent evaluation\n    eval_accumulation_steps=1,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    \n    # Early stopping to prevent overfitting on synthetic data\n    # early_stopping_patience=3,\n    \n    # WandB integration\n    report_to=\"wandb\",\n    logging_nan_inf_filter=True,\n    include_inputs_for_metrics=False,\n    \n    # Progress bar\n    disable_tqdm=False,\n    log_level=\"info\",\n    dataloader_num_workers=2,\n)\n\nprint(\"‚úÖ Training arguments configured for GRPO synthetic data\")\nprint(f\"üíæ Per device batch size: {training_args.per_device_train_batch_size}\")\nprint(f\"üìä Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\nprint(f\"üìö Learning rate: {training_args.learning_rate} (reduced for fine-tuned model)\")\nprint(f\"üìä Epochs: {training_args.num_train_epochs} (conservative approach)\")\nprint(f\"üïê Total training steps: {len(train_dataset) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps) * training_args.num_train_epochs}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T12:14:37.123751Z","iopub.execute_input":"2025-12-03T12:14:37.124084Z","iopub.status.idle":"2025-12-03T12:14:37.162655Z","shell.execute_reply.started":"2025-12-03T12:14:37.124062Z","shell.execute_reply":"2025-12-03T12:14:37.161997Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Training arguments configured for GRPO synthetic data\nüíæ Per device batch size: 4\nüìä Effective batch size: 16\nüìö Learning rate: 0.0003 (reduced for fine-tuned model)\nüìä Epochs: 5 (conservative approach)\nüïê Total training steps: 475\n","output_type":"stream"}],"execution_count":9},{"id":"ea386905","cell_type":"code","source":"# Initialize trainer\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n    dataset_num_proc=2,\n    packing=False,  # Keep False for structured GRPO format\n    args=training_args,\n)\n\nprint(\"‚úÖ SFT Trainer initialized for GRPO synthetic data\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T12:14:37.163444Z","iopub.execute_input":"2025-12-03T12:14:37.163712Z","iopub.status.idle":"2025-12-03T12:14:50.178148Z","shell.execute_reply.started":"2025-12-03T12:14:37.163684Z","shell.execute_reply":"2025-12-03T12:14:50.177172Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=8):   0%|          | 0/1525 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63f02c83a2614ea5b1628591cd8d9e4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=8):   0%|          | 0/180 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fef38c3550ab485c867f47393700986d"}},"metadata":{}},{"name":"stderr","text":"Using auto half precision backend\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ SFT Trainer initialized for GRPO synthetic data\n","output_type":"stream"}],"execution_count":10},{"id":"c6230ac6","cell_type":"markdown","source":"## üöÄ Start Training!\n\n**Estimated time**: ~30-60 min for 1 epoch (shorter due to pre-trained model)  \n**Memory usage**: ~15-16GB VRAM (longer sequences)  \n**Watch for**: Overfitting (eval loss increasing while train loss decreasing)","metadata":{}},{"id":"f7317cd7","cell_type":"code","source":"# Show GPU stats before training\ngpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"üñ•Ô∏è GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"üíæ {start_gpu_memory} GB of memory reserved.\")\nprint(f\"üéØ Training GRPO model with synthetic structured data...\")\n\n# Start training\nprint(\"\\nüöÄ Starting GRPO synthetic data training...\\n\")\ntrainer_stats = trainer.train()\n\n# Show final stats\nused_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nused_memory_for_lora = round(used_memory - start_gpu_memory, 3)\nused_percentage = round(used_memory / max_memory * 100, 3)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"‚úÖ GRPO SYNTHETIC DATA TRAINING COMPLETED!\")\nprint(\"=\"*50)\nprint(f\"‚è±Ô∏è Training time: {trainer_stats.metrics['train_runtime']:.2f} seconds\")\nprint(f\"üíæ Peak reserved memory: {used_memory} GB\")\nprint(f\"üìä Memory used for training: {used_memory_for_lora} GB\")\nprint(f\"üìà Percentage of max memory: {used_percentage}%\")\nprint(f\"üéØ Final train loss: {trainer_stats.metrics['train_loss']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T12:14:50.179278Z","iopub.execute_input":"2025-12-03T12:14:50.179521Z","iopub.status.idle":"2025-12-03T15:39:53.170412Z","shell.execute_reply.started":"2025-12-03T12:14:50.179498Z","shell.execute_reply":"2025-12-03T15:39:53.169681Z"}},"outputs":[{"name":"stdout","text":"üñ•Ô∏è GPU = Tesla T4. Max memory = 14.741 GB.\nüíæ 3.072 GB of memory reserved.\nüéØ Training GRPO model with synthetic structured data...\n\nüöÄ Starting GRPO synthetic data training...\n\n","output_type":"stream"},{"name":"stderr","text":"The following columns in the Training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\nskipped Embedding(128256, 3072, padding_idx=128004): 375.75M params\nskipped: 375.75M params\n==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 1,525 | Num Epochs = 5 | Total steps = 240\nO^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32\n \"-____-\"     Trainable parameters = 48,627,712 of 3,261,377,536 (1.49% trained)\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [240/240 3:24:12, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>0.798300</td>\n      <td>0.761347</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.714500</td>\n      <td>0.714570</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.668000</td>\n      <td>0.692364</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.593200</td>\n      <td>0.683103</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.580000</td>\n      <td>0.676438</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.514000</td>\n      <td>0.682938</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.509600</td>\n      <td>0.679975</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.500000</td>\n      <td>0.683365</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.482800</td>\n      <td>0.687958</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the Evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 180\n  Batch size = 8\nUnsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\nUsing gradient accumulation will be very slightly less accurate.\nRead more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\nSaving model checkpoint to ./outputs-grpo-synthetic/checkpoint-25\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mikeethanh--vietnamese-legal-llama3.2-3b-merged-grpo-v1/snapshots/6297650326af051fe404aa2fb940b64eba2e2503/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"dtype\": \"float16\",\n  \"eos_token_id\": 128009,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pad_token_id\": 128004,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"transformers_version\": \"4.56.2\",\n  \"unsloth_fixed\": true,\n  \"unsloth_version\": \"2025.11.6\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nThe following columns in the Evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 180\n  Batch size = 8\nSaving model checkpoint to ./outputs-grpo-synthetic/checkpoint-50\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mikeethanh--vietnamese-legal-llama3.2-3b-merged-grpo-v1/snapshots/6297650326af051fe404aa2fb940b64eba2e2503/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"dtype\": \"float16\",\n  \"eos_token_id\": 128009,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pad_token_id\": 128004,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"transformers_version\": \"4.56.2\",\n  \"unsloth_fixed\": true,\n  \"unsloth_version\": \"2025.11.6\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nThe following columns in the Evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 180\n  Batch size = 8\nSaving model checkpoint to ./outputs-grpo-synthetic/checkpoint-75\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mikeethanh--vietnamese-legal-llama3.2-3b-merged-grpo-v1/snapshots/6297650326af051fe404aa2fb940b64eba2e2503/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"dtype\": \"float16\",\n  \"eos_token_id\": 128009,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pad_token_id\": 128004,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"transformers_version\": \"4.56.2\",\n  \"unsloth_fixed\": true,\n  \"unsloth_version\": \"2025.11.6\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nThe following columns in the Evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 180\n  Batch size = 8\nSaving model checkpoint to ./outputs-grpo-synthetic/checkpoint-100\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mikeethanh--vietnamese-legal-llama3.2-3b-merged-grpo-v1/snapshots/6297650326af051fe404aa2fb940b64eba2e2503/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"dtype\": \"float16\",\n  \"eos_token_id\": 128009,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pad_token_id\": 128004,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"transformers_version\": \"4.56.2\",\n  \"unsloth_fixed\": true,\n  \"unsloth_version\": \"2025.11.6\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nDeleting older checkpoint [outputs-grpo-synthetic/checkpoint-25] due to args.save_total_limit\nThe following columns in the Evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 180\n  Batch size = 8\nSaving model checkpoint to ./outputs-grpo-synthetic/checkpoint-125\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mikeethanh--vietnamese-legal-llama3.2-3b-merged-grpo-v1/snapshots/6297650326af051fe404aa2fb940b64eba2e2503/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"dtype\": \"float16\",\n  \"eos_token_id\": 128009,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pad_token_id\": 128004,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"transformers_version\": \"4.56.2\",\n  \"unsloth_fixed\": true,\n  \"unsloth_version\": \"2025.11.6\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nDeleting older checkpoint [outputs-grpo-synthetic/checkpoint-50] due to args.save_total_limit\nThe following columns in the Evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 180\n  Batch size = 8\nSaving model checkpoint to ./outputs-grpo-synthetic/checkpoint-150\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mikeethanh--vietnamese-legal-llama3.2-3b-merged-grpo-v1/snapshots/6297650326af051fe404aa2fb940b64eba2e2503/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"dtype\": \"float16\",\n  \"eos_token_id\": 128009,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pad_token_id\": 128004,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"transformers_version\": \"4.56.2\",\n  \"unsloth_fixed\": true,\n  \"unsloth_version\": \"2025.11.6\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nDeleting older checkpoint [outputs-grpo-synthetic/checkpoint-75] due to args.save_total_limit\nThe following columns in the Evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 180\n  Batch size = 8\nSaving model checkpoint to ./outputs-grpo-synthetic/checkpoint-175\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mikeethanh--vietnamese-legal-llama3.2-3b-merged-grpo-v1/snapshots/6297650326af051fe404aa2fb940b64eba2e2503/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"dtype\": \"float16\",\n  \"eos_token_id\": 128009,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pad_token_id\": 128004,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"transformers_version\": \"4.56.2\",\n  \"unsloth_fixed\": true,\n  \"unsloth_version\": \"2025.11.6\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nDeleting older checkpoint [outputs-grpo-synthetic/checkpoint-100] due to args.save_total_limit\nThe following columns in the Evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 180\n  Batch size = 8\nSaving model checkpoint to ./outputs-grpo-synthetic/checkpoint-200\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mikeethanh--vietnamese-legal-llama3.2-3b-merged-grpo-v1/snapshots/6297650326af051fe404aa2fb940b64eba2e2503/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"dtype\": \"float16\",\n  \"eos_token_id\": 128009,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pad_token_id\": 128004,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"transformers_version\": \"4.56.2\",\n  \"unsloth_fixed\": true,\n  \"unsloth_version\": \"2025.11.6\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nDeleting older checkpoint [outputs-grpo-synthetic/checkpoint-150] due to args.save_total_limit\nThe following columns in the Evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 180\n  Batch size = 8\nSaving model checkpoint to ./outputs-grpo-synthetic/checkpoint-225\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mikeethanh--vietnamese-legal-llama3.2-3b-merged-grpo-v1/snapshots/6297650326af051fe404aa2fb940b64eba2e2503/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"dtype\": \"float16\",\n  \"eos_token_id\": 128009,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pad_token_id\": 128004,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"transformers_version\": \"4.56.2\",\n  \"unsloth_fixed\": true,\n  \"unsloth_version\": \"2025.11.6\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nDeleting older checkpoint [outputs-grpo-synthetic/checkpoint-175] due to args.save_total_limit\nSaving model checkpoint to ./outputs-grpo-synthetic/checkpoint-240\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mikeethanh--vietnamese-legal-llama3.2-3b-merged-grpo-v1/snapshots/6297650326af051fe404aa2fb940b64eba2e2503/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"dtype\": \"float16\",\n  \"eos_token_id\": 128009,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pad_token_id\": 128004,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"transformers_version\": \"4.56.2\",\n  \"unsloth_fixed\": true,\n  \"unsloth_version\": \"2025.11.6\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nDeleting older checkpoint [outputs-grpo-synthetic/checkpoint-200] due to args.save_total_limit\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from ./outputs-grpo-synthetic/checkpoint-125 (score: 0.6764376163482666).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ‚ñà‚ñÜ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÉ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñà‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñÉ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà</td></tr><tr><td>train/learning_rate</td><td>‚ñÇ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.68796</td></tr><tr><td>eval/runtime</td><td>136.1843</td></tr><tr><td>eval/samples_per_second</td><td>1.322</td></tr><tr><td>eval/steps_per_second</td><td>0.169</td></tr><tr><td>total_flos</td><td>1.3361359527642931e+17</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>240</td></tr><tr><td>train/grad_norm</td><td>0.21976</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4735</td></tr><tr><td>train_loss</td><td>0.61288</td></tr><tr><td>train_runtime</td><td>12299.9405</td></tr><tr><td>train_samples_per_second</td><td>0.62</td></tr><tr><td>train_steps_per_second</td><td>0.02</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">llama3.2-3b-grpo-synthetic-sft-v1</strong> at: <a href='https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-sft-v2/runs/lmlfz4fx' target=\"_blank\">https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-sft-v2/runs/lmlfz4fx</a><br> View project at: <a href='https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-sft-v2' target=\"_blank\">https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-sft-v2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20251203_121259-lmlfz4fx/logs</code>"},"metadata":{}},{"name":"stdout","text":"\n==================================================\n‚úÖ GRPO SYNTHETIC DATA TRAINING COMPLETED!\n==================================================\n‚è±Ô∏è Training time: 12299.94 seconds\nüíæ Peak reserved memory: 11.967 GB\nüìä Memory used for training: 8.895 GB\nüìà Percentage of max memory: 81.182%\nüéØ Final train loss: 0.6129\n","output_type":"stream"}],"execution_count":11},{"id":"59518c97","cell_type":"markdown","source":"## üìä Evaluation","metadata":{}},{"id":"469ffa60","cell_type":"code","source":"# Evaluate on validation set\nprint(\"üìä Evaluating on validation set...\\n\")\neval_results = trainer.evaluate()\n\nprint(\"=\"*50)\nprint(\"VALIDATION RESULTS - GRPO SYNTHETIC\")\nprint(\"=\"*50)\nfor key, value in eval_results.items():\n    print(f\"{key}: {value:.4f}\" if isinstance(value, float) else f\"{key}: {value}\")\n\n# Log to WandB\nwandb.log({\n    \"final_eval_loss\": eval_results['eval_loss'],\n    \"model_type\": \"grpo_synthetic_sft\"\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T15:39:53.171521Z","iopub.execute_input":"2025-12-03T15:39:53.171812Z","iopub.status.idle":"2025-12-03T15:42:09.778990Z","shell.execute_reply.started":"2025-12-03T15:39:53.171782Z","shell.execute_reply":"2025-12-03T15:42:09.777406Z"}},"outputs":[{"name":"stderr","text":"The following columns in the Evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 180\n  Batch size = 8\n","output_type":"stream"},{"name":"stdout","text":"üìä Evaluating on validation set...\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [23/23 02:10]\n    </div>\n    "},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/4116084778.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üìä Evaluating on validation set...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4491\u001b[0m         )\n\u001b[1;32m   4492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4493\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(self, logs, start_time)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(self, logs, start_time)\u001b[0m\n\u001b[1;32m   3788\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3789\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3790\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mon_log\u001b[0;34m(self, args, state, control, logs)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_log\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_prediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mcall_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             result = getattr(callback, event)(\n\u001b[0m\u001b[1;32m    557\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/integrations/integration_utils.py\u001b[0m in \u001b[0;36mon_log\u001b[0;34m(self, args, state, control, model, logs, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m             \u001b[0mnon_scalar_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msingle_value_scalars\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0mnon_scalar_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewrite_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_scalar_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnon_scalar_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train/global_step\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/preinit.py\u001b[0m in \u001b[0;36mpreinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m ) -> Callable:\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"You must call wandb.init() before {name}()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"],"ename":"Error","evalue":"You must call wandb.init() before wandb.log()","output_type":"error"}],"execution_count":12},{"id":"545a590a","cell_type":"markdown","source":"## üß™ Inference Testing - GRPO Format Validation","metadata":{}},{"id":"7b904fa0","cell_type":"code","source":"# Enable native 2x faster inference\nFastLanguageModel.for_inference(model)\n\n# GRPO format markers for validation\nreasoning_start = \"<start_working_out>\"\nreasoning_end = \"<end_working_out>\"\nsolution_start = \"<SOLUTION>\"\nsolution_end = \"</SOLUTION>\"\n\ndef test_grpo_model(user_message, max_new_tokens=512):\n    \"\"\"Test model with GRPO system prompt\"\"\"\n    \n    # GRPO system prompt\n    system_prompt = f\"\"\"B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n v·ªÅ lu·∫≠t giao th√¥ng Vi·ªát Nam. Khi tr·∫£ l·ªùi c√¢u h·ªèi, h√£y:\n1. Suy nghƒ© v√† ph√¢n t√≠ch c√¢u h·ªèi trong ph·∫ßn {reasoning_start} {reasoning_end}\n2. ƒê∆∞a ra c√¢u tr·∫£ l·ªùi ch√≠nh x√°c trong ph·∫ßn {solution_start}{solution_end}\n\nC√¢u tr·∫£ l·ªùi c·∫ßn d·ª±a tr√™n quy ƒë·ªãnh ph√°p lu·∫≠t hi·ªán h√†nh v√† ph·∫£i r√µ r√†ng, d·ªÖ hi·ªÉu.\"\"\"\n    \n    messages = [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": user_message}\n    ]\n    \n    # Apply chat template\n    prompt = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n    \n    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n    \n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=max_new_tokens,\n        temperature=0.7,\n        top_p=0.9,\n        do_sample=True,\n        use_cache=True,\n        pad_token_id=tokenizer.eos_token_id\n    )\n    \n    response = tokenizer.batch_decode(outputs)[0]\n    # Extract only the response part\n    if \"<|start_header_id|>assistant<|end_header_id|>\" in response:\n        response = response.split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1]\n        response = response.split(\"<|eot_id|>\")[0].strip()\n    \n    return response\n\ndef validate_grpo_format(response):\n    \"\"\"Validate if response follows GRPO format\"\"\"\n    has_reasoning = reasoning_start in response and reasoning_end in response\n    has_solution = solution_start in response and solution_end in response\n    \n    return {\n        \"has_reasoning\": has_reasoning,\n        \"has_solution\": has_solution,\n        \"proper_format\": has_reasoning and has_solution\n    }\n\n# Test questions\ntest_questions = [\n    \"M·ª©c ph·∫°t cho vi·ªác v∆∞·ª£t ƒë√®n ƒë·ªè ƒë·ªëi v·ªõi xe m√°y l√† bao nhi√™u?\"\n]\n\nprint(\"üß™ Testing GRPO model with structured format validation...\\n\")\nprint(\"=\"*80)\n\nformat_validation_results = []\n\nfor i, question in enumerate(test_questions, 1):\n    print(f\"\\n{'='*80}\")\n    print(f\"TEST QUESTION #{i}\")\n    print(f\"{'='*80}\")\n    print(f\"\\n‚ùì Question: {question}\")\n    \n    # Generate response\n    response = test_grpo_model(question)\n    print(f\"\\nü§ñ Model Response:\\n{response}\")\n    \n    # Validate format\n    validation = validate_grpo_format(response)\n    format_validation_results.append(validation)\n    \n    print(f\"\\nüìä Format Validation:\")\n    print(f\"   Has reasoning section: {validation['has_reasoning']} ‚úÖ\" if validation['has_reasoning'] else f\"   Has reasoning section: {validation['has_reasoning']} ‚ùå\")\n    print(f\"   Has solution section: {validation['has_solution']} ‚úÖ\" if validation['has_solution'] else f\"   Has solution section: {validation['has_solution']} ‚ùå\")\n    print(f\"   Proper GRPO format: {validation['proper_format']} ‚úÖ\" if validation['proper_format'] else f\"   Proper GRPO format: {validation['proper_format']} ‚ùå\")\n    print(f\"\\n{'='*80}\")\n\n# Summary of format validation\nproper_format_count = sum(1 for r in format_validation_results if r['proper_format'])\nprint(f\"\\nüìä GRPO FORMAT VALIDATION SUMMARY:\")\nprint(f\"   Proper format: {proper_format_count}/{len(test_questions)} ({proper_format_count/len(test_questions)*100:.1f}%)\")\n\nif proper_format_count == len(test_questions):\n    print(\"üéâ Excellent! Model consistently follows GRPO format\")\nelif proper_format_count >= len(test_questions) * 0.7:\n    print(\"‚úÖ Good! Model mostly follows GRPO format\")\nelse:\n    print(\"‚ö†Ô∏è Warning: Model needs more training on GRPO format\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T15:42:31.279456Z","iopub.execute_input":"2025-12-03T15:42:31.280159Z","iopub.status.idle":"2025-12-03T15:43:01.185023Z","shell.execute_reply.started":"2025-12-03T15:42:31.280126Z","shell.execute_reply":"2025-12-03T15:43:01.184254Z"}},"outputs":[{"name":"stdout","text":"üß™ Testing GRPO model with structured format validation...\n\n================================================================================\n\n================================================================================\nTEST QUESTION #1\n================================================================================\n\n‚ùì Question: M·ª©c ph·∫°t cho vi·ªác v∆∞·ª£t ƒë√®n ƒë·ªè ƒë·ªëi v·ªõi xe m√°y l√† bao nhi√™u?\n\nü§ñ Model Response:\n<start_working_out>\nƒê·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ m·ª©c ph·∫°t cho vi·ªác v∆∞·ª£t ƒë√®n ƒë·ªè ƒë·ªëi v·ªõi xe m√°y, tr∆∞·ªõc ti√™n c·∫ßn x√°c ƒë·ªãnh r√µ r√†ng y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng, t·ª©c l√† t√¨m hi·ªÉu v·ªÅ quy ƒë·ªãnh c·ª• th·ªÉ li√™n quan ƒë·∫øn h√†nh vi n√†y trong lu·∫≠t giao th√¥ng Vi·ªát Nam. \n\nTheo quy ƒë·ªãnh t·∫°i ƒêi·ªÅu 14 c·ªßa Lu·∫≠t Giao th√¥ng ƒë∆∞·ªùng b·ªô, vi·ªác v∆∞·ª£t ƒë√®n ƒë·ªè l√† h√†nh vi vi ph·∫°m. C·ª• th·ªÉ, kho·∫£n 3 c·ªßa ƒëi·ªÅu n√†y quy ƒë·ªãnh r·∫±ng \"Kh√¥ng ƒë∆∞·ª£c v∆∞·ª£t ƒë√®n ƒë·ªè, tr·ª´ tr∆∞·ªùng h·ª£p xe ∆∞u ti√™n.\" ƒêi·ªÅu n√†y c√≥ nghƒ©a l√† vi·ªác v∆∞·ª£t ƒë√®n ƒë·ªè kh√¥ng ch·ªâ vi ph·∫°m quy t·∫Øc giao th√¥ng m√† c√≤n c√≥ th·ªÉ d·∫´n ƒë·∫øn c√°c h√¨nh ph·∫°t h√†nh ch√≠nh.\n\nM·ª©c ph·∫°t cho h√†nh vi v∆∞·ª£t ƒë√®n ƒë·ªè ƒë·ªëi v·ªõi xe m√°y ƒë∆∞·ª£c quy ƒë·ªãnh t·∫°i Ngh·ªã ƒë·ªãnh 100/2019/Nƒê-CP, trong ƒë√≥ n√™u r√µ m·ª©c ph·∫°t c·ª• th·ªÉ cho h√†nh vi n√†y. Theo ƒë√≥, m·ª©c ph·∫°t ƒë·ªëi v·ªõi h√†nh vi v∆∞·ª£t ƒë√®n ƒë·ªè cho xe m√°y s·∫Ω l√† t·ª´ 400.000 ƒë·ªìng ƒë·∫øn 600.000 ƒë·ªìng. Ngo√†i ra, ng∆∞·ªùi vi ph·∫°m c√≤n c√≥ th·ªÉ b·ªã t∆∞·ªõc gi·∫•y ph√©p l√°i xe t·ª´ 1 ƒë·∫øn 3 th√°ng.\n\nNgo√†i ra, c·∫ßn xem x√©t c√°c tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát nh∆∞ xe ∆∞u ti√™n, trong ƒë√≥ tr∆∞·ªùng h·ª£p n√†y ƒë∆∞·ª£c ph√©p v∆∞·ª£t ƒë√®n ƒë·ªè m√† kh√¥ng b·ªã x·ª≠ ph·∫°t. Vi·ªác hi·ªÉu r√µ c√°c quy ƒë·ªãnh n√†y kh√¥ng ch·ªâ gi√∫p ng∆∞·ªùi l√°i xe tu√¢n th·ªß ph√°p lu·∫≠t m√† c√≤n ƒë·∫£m b·∫£o an to√†n cho ch√≠nh m√¨nh v√† ng∆∞·ªùi tham gia giao th√¥ng kh√°c.\n\nCu·ªëi c√πng, quy ƒë·ªãnh n√†y kh√¥ng ch·ªâ nh·∫±m m·ª•c ƒë√≠ch tr·ª´ng ph·∫°t m√† c√≤n nh·∫±m n√¢ng cao √Ω th·ª©c ch·∫•p h√†nh lu·∫≠t giao th√¥ng, gi·∫£m thi·ªÉu tai n·∫°n giao th√¥ng.\n<end_working_out>\n\n<SOLUTION>\nM·ª©c ph·∫°t cho vi·ªác v∆∞·ª£t ƒë√®n ƒë·ªè ƒë·ªëi v·ªõi xe m√°y theo quy ƒë·ªãnh c·ªßa ph√°p lu·∫≠t Vi·ªát Nam ƒë∆∞·ª£c x√°c ƒë·ªãnh t·∫°i Ngh·ªã ƒë·ªãnh 100/2019/Nƒê-CP. C·ª• th·ªÉ, ng∆∞·ªùi ƒëi·ªÅu khi·ªÉn xe m√°y tham gia giao th√¥ng ƒë∆∞·ªùng b·ªô vi ph·∫°m quy ƒë·ªãnh v·ªÅ vi·ªác v∆∞·ª£t ƒë√®n ƒë·ªè s·∫Ω b·ªã x·ª≠ ph·∫°t h√†nh ch√≠nh v·ªõi m·ª©c ph·∫°t t·ª´ 400.000 ƒë·ªìng ƒë·∫øn 600.000 ƒë·ªìng. \n\nƒêi·ªÅu 14 c·ªßa Lu·∫≠t Giao th√¥ng ƒë∆∞·ªùng b·ªô quy ƒë·ªãnh r√µ r√†ng r·∫±ng \"Kh√¥ng ƒë∆∞·ª£c v∆∞·ª£t ƒë√®n ƒë·ªè, tr·ª´ tr∆∞·ªùng h·ª£p xe ∆∞u ti√™n.\" ƒêi·ªÅu n√†y c√≥ nghƒ©a l√† b·∫•t k·ªÉ xe n√†o kh√¥ng thu·ªôc danh s√°ch xe ∆∞u ti√™n, vi·ªác v∆∞·ª£t ƒë√®n ƒë·ªè ƒë·ªÅu l√† h√†nh vi vi ph·∫°m. \n\nNgo√†i m·ª©c ph·∫°t ti·ªÅn, ng∆∞·ªùi vi ph·∫°m c√≤n c√≥ th·ªÉ b·ªã t∆∞·ªõc quy·ªÅn s·ª≠ d·ª•ng gi·∫•y ph√©p l√°i xe t·ª´ 1 ƒë·∫øn 3 th√°ng,\n\nüìä Format Validation:\n   Has reasoning section: True ‚úÖ\n   Has solution section: False ‚ùå\n   Proper GRPO format: False ‚ùå\n\n================================================================================\n\nüìä GRPO FORMAT VALIDATION SUMMARY:\n   Proper format: 0/1 (0.0%)\n‚ö†Ô∏è Warning: Model needs more training on GRPO format\n","output_type":"stream"}],"execution_count":13},{"id":"46afa2dd","cell_type":"markdown","source":"## üíæ Save Model","metadata":{}},{"id":"af9f9461","cell_type":"code","source":"# Optional: Save merged model (full size ~6GB)\nmodel.save_pretrained_merged(\"grpo_synthetic_merged\", tokenizer, save_method=\"merged_16bit\")\nprint(\"‚úÖ GRPO synthetic merged model saved to: grpo_synthetic_merged/\")\nprint(\"üéØ This model now has: Base ‚Üí GRPO training ‚Üí Synthetic data SFT\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T15:43:47.264406Z","iopub.execute_input":"2025-12-03T15:43:47.264685Z","iopub.status.idle":"2025-12-03T15:44:44.379688Z","shell.execute_reply.started":"2025-12-03T15:43:47.264664Z","shell.execute_reply":"2025-12-03T15:44:44.378867Z"}},"outputs":[{"name":"stderr","text":"Configuration saved in grpo_synthetic_merged/config.json\n","output_type":"stream"},{"name":"stdout","text":"Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef8cb69d78c248179de204e5baa779c2"}},"metadata":{}},{"name":"stdout","text":"Checking cache directory for required files...\n","output_type":"stream"},{"name":"stderr","text":"Unsloth: Copying 2 files from cache to `grpo_synthetic_merged`: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:11<00:00,  5.84s/it]\n","output_type":"stream"},{"name":"stdout","text":"Successfully copied all 2 files from cache to `grpo_synthetic_merged`\nChecking cache directory for required files...\nCache check failed: tokenizer.model not found in local cache.\nNot all required files found in cache. Will proceed with downloading.\n","output_type":"stream"},{"name":"stderr","text":"Unsloth: Preparing safetensor model files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 19972.88it/s]\nUnsloth: Merging weights into 16bit: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:42<00:00, 21.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Merge process complete. Saved to `/kaggle/working/grpo_synthetic_merged`\n‚úÖ GRPO synthetic merged model saved to: grpo_synthetic_merged/\nüéØ This model now has: Base ‚Üí GRPO training ‚Üí Synthetic data SFT\n","output_type":"stream"}],"execution_count":14},{"id":"aaf0930b","cell_type":"markdown","source":"## üì§ Model Upload & Export","metadata":{}},{"id":"2cf0aa5f","cell_type":"code","source":"# Upload merged model to HuggingFace Hub (gi·∫£i ph√°p cho file l·ªõn!)\n# B∆∞·ªõc 1: T·∫°o HuggingFace account t·∫°i https://huggingface.co/join\n# B∆∞·ªõc 2: T·∫°o token t·∫°i https://huggingface.co/settings/tokens (ch·ªçn \"Write\" permission)\n# B∆∞·ªõc 3: Th√™m token v√†o Kaggle Secrets v·ªõi key \"HF_TOKEN\"\n\nimport os\n\nif os.path.exists(\"/kaggle/working\"):\n    print(\"üöÄ Uploading model to HuggingFace Hub...\")\n    print(\"=\"*70)\n    \n    try:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n        \n        from huggingface_hub import HfApi, login\n        \n        # Login to HuggingFace\n        login(token=hf_token)\n        print(\"‚úÖ Logged in to HuggingFace\")\n        \n        # Thay YOUR_USERNAME b·∫±ng username HuggingFace c·ªßa b·∫°n\n        YOUR_HF_USERNAME = \"mikeethanh\"  # ‚ö†Ô∏è S·ª¨A D√íNG N√ÄY!\n        repo_name = f\"{YOUR_HF_USERNAME}/vietnamese-legal-llama3.2-3b-merged-sft-v3\"\n        \n        print(f\"\\nüì§ Uploading to: {repo_name}\")\n        print(\"‚è≥ ƒêang upload ~6GB, c√≥ th·ªÉ m·∫•t 10-15 ph√∫t...\\n\")\n        \n        # Upload merged model\n        if os.path.exists(\"grpo_synthetic_merged\"):\n            from huggingface_hub import create_repo, upload_folder\n            \n            # Create repo (public)\n            try:\n                create_repo(repo_name, repo_type=\"model\", exist_ok=True)\n                print(f\"‚úÖ Repository created: https://huggingface.co/{repo_name}\")\n            except:\n                print(f\"‚ÑπÔ∏è Repository already exists: https://huggingface.co/{repo_name}\")\n            \n            # Upload folder\n            upload_folder(\n                folder_path=\"grpo_synthetic_merged\",\n                repo_id=repo_name,\n                commit_message=\"Vietnamese Legal AI - Llama 3.2 3B Merged Model\",\n            )\n            \n            print(\"\\n\" + \"=\"*70)\n            print(\"‚úÖ UPLOAD TH√ÄNH C√îNG!\")\n            print(\"=\"*70)\n            print(f\"\\nüì• Download model v·ªÅ m√°y b·∫±ng c√°ch:\")\n            print(f\"   git clone https://huggingface.co/{repo_name}\")\n            print(f\"\\nüåê Ho·∫∑c xem tr√™n web:\")\n            print(f\"   https://huggingface.co/{repo_name}\")\n            print(\"\\nüí° Model ƒë√£ public, ai c≈©ng c√≥ th·ªÉ download!\")\n        else:\n            print(\"‚ö†Ô∏è Folder 'vietnamese_legal_merged' not found!\")\n            \n    except Exception as e:\n        print(f\"‚ùå Error: {e}\")\n        print(\"\\nüìù H∆∞·ªõng d·∫´n fix:\")\n        print(\"  1. T·∫°o account t·∫°i: https://huggingface.co/join\")\n        print(\"  2. T·∫°o token t·∫°i: https://huggingface.co/settings/tokens\")\n        print(\"  3. Kaggle: Add-ons ‚Üí Secrets ‚Üí Add 'HF_TOKEN'\")\n        print(\"  4. S·ª≠a YOUR_USERNAME trong code\")\n        \nelse:\n    print(\"‚ÑπÔ∏è This cell only works on Kaggle\")\n    print(\"üí° For local, use: model.push_to_hub() directly\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T15:44:53.965055Z","iopub.execute_input":"2025-12-03T15:44:53.965338Z","iopub.status.idle":"2025-12-03T15:46:00.599693Z","shell.execute_reply.started":"2025-12-03T15:44:53.965317Z","shell.execute_reply":"2025-12-03T15:46:00.598977Z"}},"outputs":[{"name":"stdout","text":"üöÄ Uploading model to HuggingFace Hub...\n======================================================================\n‚úÖ Logged in to HuggingFace\n\nüì§ Uploading to: mikeethanh/vietnamese-legal-llama3.2-3b-merged-sft-v3\n‚è≥ ƒêang upload ~6GB, c√≥ th·ªÉ m·∫•t 10-15 ph√∫t...\n\n‚úÖ Repository created: https://huggingface.co/mikeethanh/vietnamese-legal-llama3.2-3b-merged-sft-v3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c30fced548547718d96e8a40db71f7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b761fa02cdba4c29952fa663856b23b2"}},"metadata":{}},{"name":"stdout","text":"\n======================================================================\n‚úÖ UPLOAD TH√ÄNH C√îNG!\n======================================================================\n\nüì• Download model v·ªÅ m√°y b·∫±ng c√°ch:\n   git clone https://huggingface.co/mikeethanh/vietnamese-legal-llama3.2-3b-merged-sft-v3\n\nüåê Ho·∫∑c xem tr√™n web:\n   https://huggingface.co/mikeethanh/vietnamese-legal-llama3.2-3b-merged-sft-v3\n\nüí° Model ƒë√£ public, ai c≈©ng c√≥ th·ªÉ download!\n","output_type":"stream"}],"execution_count":15},{"id":"2877158b","cell_type":"markdown","source":"## üìä Quantization Export","metadata":{}},{"id":"ad7eba56","cell_type":"code","source":"# Export to GGUF for deployment\nquantization_methods = [\n    \"q8_0\",    # Fast inference, good quality\n    \"q4_k_m\",  # Smaller size, good balance\n]\n\nfor method in quantization_methods:\n    print(f\"\\nüì¶ Exporting GRPO synthetic model to {method.upper()}...\")\n    model.save_pretrained_gguf(\n        \"grpo_synthetic_model\",\n        tokenizer,\n        quantization_method=method,\n    )\n    print(f\"‚úÖ Exported: grpo_synthetic_model-{method.upper()}.gguf\")\n\nprint(\"\\n‚úÖ All GGUF exports completed!\")\nprint(\"üöÄ Ready for deployment with Ollama or llama.cpp\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T15:42:09.783892Z","iopub.status.idle":"2025-12-03T15:42:09.784228Z","shell.execute_reply.started":"2025-12-03T15:42:09.784057Z","shell.execute_reply":"2025-12-03T15:42:09.784080Z"}},"outputs":[],"execution_count":null},{"id":"801b7b3b","cell_type":"markdown","source":"## üéâ Training Summary & Cleanup","metadata":{}},{"id":"aaa02820","cell_type":"code","source":"# Finish WandB run\nwandb.finish()\n\n# Clear GPU memory\ndel model\ndel trainer\ngc.collect()\ntorch.cuda.empty_cache()\n\nprint(\"‚úÖ GRPO Synthetic Data Training completed successfully!\")\nprint(\"\\nüìä FINAL SUMMARY:\")\nprint(\"=\"*60)\nprint(f\"ü§ñ Base Model: mikeethanh/vietnamese-legal-llama3.2-3b-merged-grpo\")\nprint(f\"üìä Training samples: {len(train_data):,} (synthetic GRPO format)\")\nprint(f\"üìä Validation samples: {len(val_data):,}\")\nprint(f\"üìä Test samples: {len(test_data):,}\")\nprint(f\"‚è±Ô∏è Training time: ~{trainer_stats.metrics['train_runtime']/60:.1f} minutes\")\nprint(f\"üéØ Final eval loss: {eval_results['eval_loss']:.4f}\")\n\nprint(\"\\nüìÇ SAVED OUTPUTS:\")\nprint(\"  ‚úÖ LoRA adapters: grpo_synthetic_lora/\")\nprint(\"  ‚úÖ Merged model: grpo_synthetic_merged/\")\nprint(\"  ‚úÖ GGUF models: grpo_synthetic_model-*.gguf\")\n\nprint(\"\\nüéØ MODEL EVOLUTION COMPLETE:\")\nprint(\"  1Ô∏è‚É£ Base: Llama-3.2-3B-Instruct\")\nprint(\"  2Ô∏è‚É£ GRPO: Reinforcement learning v·ªõi reward functions\")\nprint(\"  3Ô∏è‚É£ SFT: Synthetic data v·ªõi structured reasoning format\")\n\nprint(\"\\nüöÄ NEXT STEPS:\")\nprint(\"  1. Test model on real user queries\")\nprint(\"  2. Validate GRPO format consistency\")\nprint(\"  3. Deploy and collect feedback\")\nprint(\"  4. Iterate with more synthetic data if needed\")\n\nprint(\"\\nüéâ Training pipeline complete! Model ready for deployment.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T15:42:09.785392Z","iopub.status.idle":"2025-12-03T15:42:09.785680Z","shell.execute_reply.started":"2025-12-03T15:42:09.785544Z","shell.execute_reply":"2025-12-03T15:42:09.785554Z"}},"outputs":[],"execution_count":null}]}