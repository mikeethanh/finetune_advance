{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13952689,"sourceType":"datasetVersion","datasetId":8893341}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"f71fe92e","cell_type":"markdown","source":"## ğŸ“‹ Setup & Installation","metadata":{}},{"id":"f984caaf","cell_type":"code","source":"%%capture\nimport os, re\nif \"COLAB_\" not in \"\".join(os.environ.keys()):\n    !pip install unsloth\nelse:\n    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n    import torch; v = re.match(r\"[0-9]{1,}\\.[0-9]{1,}\", str(torch.__version__)).group(0)\n    xformers = \"xformers==\" + (\"0.0.33.post1\" if v==\"2.9\" else \"0.0.32.post2\" if v==\"2.8\" else \"0.0.29.post3\")\n    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n    !pip install sentencepiece protobuf \"datasets==4.3.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n    !pip install --no-deps unsloth\n!pip install transformers==4.56.2\n!pip install --no-deps trl==0.22.2\n!pip install wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T03:43:00.419837Z","iopub.execute_input":"2025-12-02T03:43:00.420567Z","iopub.status.idle":"2025-12-02T03:43:37.212268Z","shell.execute_reply.started":"2025-12-02T03:43:00.420541Z","shell.execute_reply":"2025-12-02T03:43:37.211262Z"}},"outputs":[],"execution_count":2},{"id":"0c48c422","cell_type":"code","source":"import os\nimport json\nimport torch\nimport wandb\nfrom datasets import Dataset, load_dataset\nfrom unsloth import FastLanguageModel\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport gc\n\n# Check GPU\nprint(f\"GPU Available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T03:44:02.077384Z","iopub.execute_input":"2025-12-02T03:44:02.078012Z","iopub.status.idle":"2025-12-02T03:44:43.201605Z","shell.execute_reply.started":"2025-12-02T03:44:02.077977Z","shell.execute_reply":"2025-12-02T03:44:43.200789Z"}},"outputs":[{"name":"stdout","text":"ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-12-02 03:44:07.935717: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764647048.184811      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764647048.243987      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\nGPU Available: True\nGPU Name: Tesla T4\nGPU Memory: 15.83 GB\n","output_type":"stream"}],"execution_count":3},{"id":"8d854241","cell_type":"markdown","source":"## ğŸ” WandB Login (for monitoring)","metadata":{}},{"id":"4aae7ae2","cell_type":"code","source":"# Login to WandB for experiment tracking\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_api_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n\n# Login with API key from Kaggle Secrets\nwandb.login(key=wandb_api_key)\n\n\n# Initialize WandB project with GRPO synthetic data config\nwandb.init(\n    project=\"vietnamese-legal-ai-grpo\",\n    name=\"llama3.2-3b-grpo-synthetic-sft-v1\",\n    config={\n        \"base_model\": \"mikeethanh/vietnamese-legal-llama3.2-3b-merged-grpo\",\n        \"dataset\": \"synthetic_legal_qa_grpo_training.jsonl\",\n        \"task\": \"structured_legal_qa\",\n        \"language\": \"vietnamese\",\n        \"format\": \"grpo_structured\",\n        \"max_seq_length\": 2048,  # Increased for structured format\n        \"lora_r\": 16,  # Reduced since base model already fine-tuned\n        \"lora_alpha\": 16,\n        \"learning_rate\": 1e-4,  # Lower LR for already fine-tuned model\n        \"num_epochs\": 1,  # Less epochs needed\n        \"batch_size\": 2,\n        \"gradient_accumulation\": 8,\n        \"effective_batch_size\": 16,\n    },\n    settings=wandb.Settings(\n        _disable_meta=False,\n        _disable_stats=False,\n    )\n)\n\nprint(\"âœ… WandB initialized for GRPO synthetic data training\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T03:44:57.140251Z","iopub.execute_input":"2025-12-02T03:44:57.140707Z","iopub.status.idle":"2025-12-02T03:45:11.567881Z","shell.execute_reply.started":"2025-12-02T03:44:57.140684Z","shell.execute_reply":"2025-12-02T03:45:11.566892Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmikeethanh04\u001b[0m (\u001b[33mmikeethanh04-student\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251202_034504-5s0e4g20</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-grpo/runs/5s0e4g20' target=\"_blank\">llama3.2-3b-grpo-synthetic-sft-v1</a></strong> to <a href='https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-grpo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-grpo' target=\"_blank\">https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-grpo</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-grpo/runs/5s0e4g20' target=\"_blank\">https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-grpo/runs/5s0e4g20</a>"},"metadata":{}},{"name":"stdout","text":"âœ… WandB initialized for GRPO synthetic data training\n","output_type":"stream"}],"execution_count":5},{"id":"1914eb73","cell_type":"markdown","source":"## âš™ï¸ Model Configuration - GRPO Merged Model\n\n### Táº¡i sao sá»­ dá»¥ng GRPO merged model?\n- âœ… **Already GRPO trained**: Model Ä‘Ã£ Ä‘Æ°á»£c train vá»›i GRPO format\n- âœ… **Structured reasoning**: ÄÃ£ biáº¿t format `<start_working_out>` vÃ  `<SOLUTION>`\n- âœ… **Domain adapted**: ÄÃ£ fine-tune trÃªn legal domain\n- âœ… **Consistent format**: Sáº½ dá»… dÃ ng há»c synthetic data cÃ¹ng format\n- âœ… **Less training needed**: Chá»‰ cáº§n Ã­t epochs Ä‘á»ƒ adapt vá»›i synthetic data","metadata":{}},{"id":"cb2b08f8","cell_type":"code","source":"# Model configuration for GRPO merged model\nmax_seq_length = 2048  # Increased for structured format with reasoning\ndtype = None  # Auto-detect. Use Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True  # Use 4bit quantization to reduce memory usage\n\n# Load the GRPO merged model\nmodel_name = \"mikeethanh/vietnamese-legal-llama3.2-3b-merged-sft-v1\"  # Your GRPO merged model\n\nprint(f\"ğŸ”„ Loading GRPO merged model: {model_name}\")\nprint(\"âš ï¸ This model already contains GRPO training adaptations\")\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=model_name,\n    max_seq_length=max_seq_length,\n    dtype=dtype,\n    load_in_4bit=load_in_4bit,\n)\n\nprint(f\"âœ… GRPO merged model loaded: {model_name}\")\nprint(f\"ğŸ“ Max sequence length: {max_seq_length}\")\nprint(f\"ğŸ”¢ 4-bit quantization: {load_in_4bit}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T03:45:34.280312Z","iopub.execute_input":"2025-12-02T03:45:34.280587Z","iopub.status.idle":"2025-12-02T03:46:13.304062Z","shell.execute_reply.started":"2025-12-02T03:45:34.280568Z","shell.execute_reply":"2025-12-02T03:46:13.303288Z"}},"outputs":[{"name":"stdout","text":"ğŸ”„ Loading GRPO merged model: mikeethanh/vietnamese-legal-llama3.2-3b-merged-sft-v1\nâš ï¸ This model already contains GRPO training adaptations\n==((====))==  Unsloth 2025.11.6: Fast Llama patching. Transformers: 4.56.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"570e7b23007a4091a1b7ba305d998d3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d63d658610e4cdd9433caa7dd2fc166"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"534d5df0f23b4d71b63f1730f431483a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7609a611f3a14eca998a0a3f095e96a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0611639c47740709f13b6503b9ae3a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef913c5310734a2da0342c6c4db22cd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1122f8ee68724696b7f98cf8129d2c3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97e3b13992b24984aa6ebf8b179ddf18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.jinja:   0%|          | 0.00/943 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9bea8f5db0a428cadcd7f6ab383d17f"}},"metadata":{}},{"name":"stdout","text":"âœ… GRPO merged model loaded: mikeethanh/vietnamese-legal-llama3.2-3b-merged-sft-v1\nğŸ“ Max sequence length: 2048\nğŸ”¢ 4-bit quantization: True\n","output_type":"stream"}],"execution_count":6},{"id":"202967d3","cell_type":"markdown","source":"## ğŸ¯ LoRA Configuration - Lighter for Already Fine-tuned Model\n\n### LoRA Parameters cho model Ä‘Ã£ fine-tune:\n- **r (rank)**: 8-16 thay vÃ¬ 32 (model Ä‘Ã£ cÃ³ knowledge)\n- **lora_alpha**: TÆ°Æ¡ng á»©ng vá»›i r\n- **learning_rate**: Tháº¥p hÆ¡n (5e-5 Ä‘áº¿n 1e-4)\n- **epochs**: 1-2 epochs thay vÃ¬ 3+","metadata":{}},{"id":"55cdfd49","cell_type":"code","source":"# Apply LoRA adapters vá»›i settings nháº¹ hÆ¡n cho model Ä‘Ã£ fine-tune\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r=32,  # Reduced from 32 since model is already fine-tuned\n    target_modules=[\n        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n        \"gate_proj\", \"up_proj\", \"down_proj\",\n    ],  # All attention & MLP layers\n    lora_alpha=32,  # Equal to r\n    lora_dropout=0,  # 0 is optimized by Unsloth\n    bias=\"none\",  # \"none\" is optimized\n    use_gradient_checkpointing=\"unsloth\",  # Unsloth's long context support\n    random_state=3407,  # For reproducibility\n    use_rslora=False,  # Rank stabilized LoRA\n    loftq_config=None,  # LoftQ quantization\n)\n\nprint(\"âœ… LoRA adapters applied (lighter config for pre-trained model)\")\nprint(f\"ğŸ“Š Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\nprint(f\"ğŸ“Š Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\nprint(f\"ğŸ’¡ Trainable ratio: {100 * sum(p.numel() for p in model.parameters() if p.requires_grad) / sum(p.numel() for p in model.parameters()):.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T03:46:25.505655Z","iopub.execute_input":"2025-12-02T03:46:25.506049Z","iopub.status.idle":"2025-12-02T03:46:32.558403Z","shell.execute_reply.started":"2025-12-02T03:46:25.506017Z","shell.execute_reply":"2025-12-02T03:46:32.557583Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.11.6 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","output_type":"stream"},{"name":"stdout","text":"âœ… LoRA adapters applied (lighter config for pre-trained model)\nğŸ“Š Trainable parameters: 48,627,712\nğŸ“Š Total parameters: 1,852,091,392\nğŸ’¡ Trainable ratio: 2.63%\n","output_type":"stream"}],"execution_count":7},{"id":"f09db0d2","cell_type":"markdown","source":"## ğŸ“Š GRPO Synthetic Data Preparation\n\n### Expected Data Format:\n```json\n{\n  \"messages\": [\n    {\"role\": \"system\", \"content\": \"System prompt vá»›i GRPO format\"},\n    {\"role\": \"user\", \"content\": \"CÃ¢u há»i phÃ¡p luáº­t\"},\n    {\"role\": \"assistant\", \"content\": \"<start_working_out>\\nSuy nghÄ©...\\n<end_working_out>\\n\\n<SOLUTION>CÃ¢u tráº£ lá»i</SOLUTION>\"}\n  ]\n}\n```","metadata":{}},{"id":"d475ba63","cell_type":"code","source":"# Load GRPO synthetic data\n# Update path to your synthetic data file\ndata_path = \"/kaggle/input/synthetic-legal-2k/synthetic_legal_qa_grpo_format.jsonl\"  # Correct path\n\nprint(f\"ğŸ” Looking for GRPO synthetic data at: {data_path}\")\n\n# Check if file exists\nif not os.path.exists(data_path):\n    print(f\"âš ï¸ Data file not found at {data_path}\")\n    print(\"ğŸ“¥ Please check the path or upload the file\")\n    \n    # Alternative: Try different common paths\n    alternative_paths = [\n        \"/content/synthetic_legal_qa_grpo_format.jsonl\",  # Colab\n        \"/kaggle/input/grpo-synthetic-data/synthetic_legal_qa_grpo_format.jsonl\",  # Kaggle\n        \"synthetic_legal_qa_grpo_format.jsonl\",  # Current directory\n    ]\n    \n    for alt_path in alternative_paths:\n        if os.path.exists(alt_path):\n            data_path = alt_path\n            print(f\"âœ… Found data at alternative path: {data_path}\")\n            break\n    else:\n        print(\"âŒ Please ensure the GRPO synthetic data file is available\")\n        raise FileNotFoundError(f\"Data file not found: {data_path}\")\n\n# Load JSONL data and convert to messages format\ndata = []\nwith open(data_path, 'r', encoding='utf-8') as f:\n    for line in f:\n        item = json.loads(line)\n        # Convert from question/answer format to messages format\n        messages_item = {\n            \"messages\": [\n                {\n                    \"role\": \"system\", \n                    \"content\": \"Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn vá» luáº­t giao thÃ´ng Viá»‡t Nam. Khi tráº£ lá»i cÃ¢u há»i, hÃ£y: 1. Suy nghÄ© vÃ  phÃ¢n tÃ­ch cÃ¢u há»i trong pháº§n <start_working_out> <end_working_out> 2. ÄÆ°a ra cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c trong pháº§n <SOLUTION></SOLUTION>\"\n                },\n                {\n                    \"role\": \"user\", \n                    \"content\": item[\"question\"]\n                },\n                {\n                    \"role\": \"assistant\", \n                    \"content\": item[\"answer\"]\n                }\n            ]\n        }\n        data.append(messages_item)\n\nprint(f\"\\nğŸ“Š Loaded {len(data):,} GRPO training samples\")\nprint(f\"ğŸ“Š Converted from question/answer format to messages format\")\n\n# Show sample\nprint(\"\\nğŸ“ Sample GRPO data structure:\")\nsample = data[0]\nprint(f\"Keys: {list(sample.keys())}\")\nif \"messages\" in sample:\n    print(f\"\\nMessages structure:\")\n    for i, msg in enumerate(sample[\"messages\"]):\n        content_preview = msg[\"content\"][:100] + \"...\" if len(msg[\"content\"]) > 100 else msg[\"content\"]\n        print(f\"  {i+1}. {msg['role']}: {content_preview}\")\n        \n# Validate GRPO format\ngrpo_format_count = 0\nfor item in data[:100]:  # Check first 100 samples\n    if \"messages\" in item:\n        for msg in item[\"messages\"]:\n            if msg[\"role\"] == \"assistant\":\n                if \"<start_working_out>\" in msg[\"content\"] and \"<SOLUTION>\" in msg[\"content\"]:\n                    grpo_format_count += 1\n                break\n\nprint(f\"\\nâœ… GRPO format validation: {grpo_format_count}/100 samples have proper structure\")\nif grpo_format_count >= 50:\n    print(\"ğŸ‰ Excellent! Data has good GRPO format compliance\")\nelse:\n    print(\"âš ï¸ Warning: Low GRPO format compliance. Check data generation.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T03:53:03.476959Z","iopub.execute_input":"2025-12-02T03:53:03.477262Z","iopub.status.idle":"2025-12-02T03:53:03.530042Z","shell.execute_reply.started":"2025-12-02T03:53:03.477240Z","shell.execute_reply":"2025-12-02T03:53:03.529283Z"}},"outputs":[{"name":"stdout","text":"ğŸ” Looking for GRPO synthetic data at: /kaggle/input/synthetic-legal-2k/synthetic_legal_qa_grpo_format.jsonl\n\nğŸ“Š Loaded 2,121 GRPO training samples\nğŸ“Š Converted from question/answer format to messages format\n\nğŸ“ Sample GRPO data structure:\nKeys: ['messages']\n\nMessages structure:\n  1. system: Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn vá» luáº­t giao thÃ´ng Viá»‡t Nam. Khi tráº£ lá»i cÃ¢u há»i, hÃ£y: 1. Suy nghÄ© vÃ  ph...\n  2. user: Cá»•ng thÃ´ng tin Ä‘iá»‡n tá»­ Bá»™ TÆ° phÃ¡p lÃ  gÃ¬?\n  3. assistant: <start_working_out>\nCÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng mong muá»‘n tÃ¬m hiá»ƒu vá» Cá»•ng thÃ´ng tin Ä‘iá»‡n tá»­ Bá»™ TÆ° phÃ¡p, ...\n\nâœ… GRPO format validation: 100/100 samples have proper structure\nğŸ‰ Excellent! Data has good GRPO format compliance\n","output_type":"stream"}],"execution_count":11},{"id":"d8359083","cell_type":"code","source":"# Split data: 85% train, 10% validation, 5% test (less aggressive split for synthetic data)\ntrain_data, temp_data = train_test_split(data, test_size=0.15, random_state=42)\nval_data, test_data = train_test_split(temp_data, test_size=0.33, random_state=42)  # 5% test, 10% val\n\nprint(f\"ğŸ“Š Train: {len(train_data):,} samples ({len(train_data)/len(data)*100:.1f}%)\")\nprint(f\"ğŸ“Š Validation: {len(val_data):,} samples ({len(val_data)/len(data)*100:.1f}%)\")\nprint(f\"ğŸ“Š Test: {len(test_data):,} samples ({len(test_data)/len(data)*100:.1f}%)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T03:53:14.015585Z","iopub.execute_input":"2025-12-02T03:53:14.015954Z","iopub.status.idle":"2025-12-02T03:53:14.026365Z","shell.execute_reply.started":"2025-12-02T03:53:14.015929Z","shell.execute_reply":"2025-12-02T03:53:14.025729Z"}},"outputs":[{"name":"stdout","text":"ğŸ“Š Train: 1,802 samples (85.0%)\nğŸ“Š Validation: 213 samples (10.0%)\nğŸ“Š Test: 106 samples (5.0%)\n","output_type":"stream"}],"execution_count":12},{"id":"c48f0387","cell_type":"markdown","source":"## ğŸ“ Chat Template cho GRPO Format\n\nData Ä‘Ã£ cÃ³ format messages, chá»‰ cáº§n convert sang text format cho training:","metadata":{}},{"id":"70ff2513","cell_type":"code","source":"# Convert to HuggingFace Dataset and format for Unsloth\nprint(\"ğŸ”„ Converting data to HuggingFace Dataset format...\")\n\ndef format_chat_for_unsloth(examples):\n    \"\"\"Format chat data for Unsloth training\"\"\"\n    texts = []\n    \n    # Handle batch processing\n    if isinstance(examples, dict) and \"messages\" in examples:\n        # Single example\n        examples = [examples]\n    elif isinstance(examples, dict) and isinstance(examples.get(\"messages\", []), list) and len(examples[\"messages\"]) > 0 and isinstance(examples[\"messages\"][0], list):\n        # Batch of examples where examples[\"messages\"] is a list of message lists\n        examples = [{\"messages\": msg_list} for msg_list in examples[\"messages\"]]\n    elif isinstance(examples, list):\n        # Already a list of examples\n        pass\n    else:\n        # Convert from dataset format\n        if \"messages\" in examples and isinstance(examples[\"messages\"], list):\n            if len(examples[\"messages\"]) > 0 and isinstance(examples[\"messages\"][0], list):\n                # Batch format: examples[\"messages\"] = [msg_list1, msg_list2, ...]\n                examples = [{\"messages\": msg_list} for msg_list in examples[\"messages\"]]\n            else:\n                # Single example wrapped in batch\n                examples = [examples]\n    \n    for example in examples:\n        messages = example[\"messages\"]\n        \n        # Extract parts from messages\n        system_msg = \"\"\n        user_msg = \"\"\n        assistant_msg = \"\"\n        \n        for msg in messages:\n            if msg[\"role\"] == \"system\":\n                system_msg = msg[\"content\"]\n            elif msg[\"role\"] == \"user\":\n                user_msg = msg[\"content\"]\n            elif msg[\"role\"] == \"assistant\":\n                assistant_msg = msg[\"content\"]\n        \n        # Format for Unsloth training (ChatML-like format)\n        conversation = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\n{system_msg}<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n{user_msg}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n{assistant_msg}<|eot_id|>\"\"\"\n        \n        texts.append(conversation)\n    \n    return {\"text\": texts}\n\n# Convert to HuggingFace Dataset\ntrain_dataset = Dataset.from_list(train_data)\nval_dataset = Dataset.from_list(val_data)\ntest_dataset = Dataset.from_list(test_data)\n\nprint(\"âœ… Datasets created successfully\")\nprint(f\"ğŸ“Š Train dataset: {len(train_dataset)} samples\")\nprint(f\"ğŸ“Š Validation dataset: {len(val_dataset)} samples\") \nprint(f\"ğŸ“Š Test dataset: {len(test_dataset)} samples\")\n\n# Format for Unsloth training\nprint(\"ğŸ”„ Formatting data for Unsloth training...\")\n\ntrain_dataset = train_dataset.map(\n    format_chat_for_unsloth, \n    batched=True,\n    remove_columns=train_dataset.column_names\n)\n\nval_dataset = val_dataset.map(\n    format_chat_for_unsloth, \n    batched=True,\n    remove_columns=val_dataset.column_names\n)\n\nprint(\"âœ… Data formatted for Unsloth training\")\nprint(\"\\nğŸ“ Example formatted conversation:\")\nprint(train_dataset[0]['text'][:800] + \"...\")\n\n# Show token statistics\nprint(\"\\nğŸ“Š Dataset Statistics:\")\nprint(f\"ğŸ“ Train samples: {len(train_dataset)}\")\nprint(f\"ğŸ“ Val samples: {len(val_dataset)}\")\nif len(train_dataset) > 0:\n    sample_text = train_dataset[0]['text']\n    sample_tokens = len(tokenizer.encode(sample_text))\n    print(f\"ğŸ“ Sample text length: {sample_tokens} tokens\")\n    print(f\"ğŸ“ Estimated max tokens needed: {sample_tokens}\")\n\n    # Check if sequence is too long\n    if sample_tokens > max_seq_length:\n        print(f\"âš ï¸ Warning: Sample length ({sample_tokens}) exceeds max_seq_length ({max_seq_length})\")\n        print(\"ğŸ’¡ Consider increasing max_seq_length or truncating data\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T03:54:49.459164Z","iopub.execute_input":"2025-12-02T03:54:49.459710Z","iopub.status.idle":"2025-12-02T03:54:49.622976Z","shell.execute_reply.started":"2025-12-02T03:54:49.459687Z","shell.execute_reply":"2025-12-02T03:54:49.622383Z"}},"outputs":[{"name":"stdout","text":"ğŸ”„ Converting data to HuggingFace Dataset format...\nâœ… Datasets created successfully\nğŸ“Š Train dataset: 1802 samples\nğŸ“Š Validation dataset: 213 samples\nğŸ“Š Test dataset: 106 samples\nğŸ”„ Formatting data for Unsloth training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1802 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b21400d5c4bb423fb0c48b17a9f57d76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/213 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3299afe40ab427e97bca3a36263c45d"}},"metadata":{}},{"name":"stdout","text":"âœ… Data formatted for Unsloth training\n\nğŸ“ Example formatted conversation:\n<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nBáº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn vá» luáº­t giao thÃ´ng Viá»‡t Nam. Khi tráº£ lá»i cÃ¢u há»i, hÃ£y: 1. Suy nghÄ© vÃ  phÃ¢n tÃ­ch cÃ¢u há»i trong pháº§n <start_working_out> <end_working_out> 2. ÄÆ°a ra cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c trong pháº§n <SOLUTION></SOLUTION><|eot_id|><|start_header_id|>user<|end_header_id|>\n\nQuy Ä‘á»‹nh vá» tá»‘c Ä‘á»™ tá»‘i Ä‘a cho xe cÆ¡ giá»›i trÃªn Ä‘Æ°á»ng cao tá»‘c lÃ  gÃ¬?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n<start_working_out>\nNgÆ°á»i dÃ¹ng muá»‘n biáº¿t quy Ä‘á»‹nh vá» tá»‘c Ä‘á»™ tá»‘i Ä‘a cho xe cÆ¡ giá»›i trÃªn Ä‘Æ°á»ng cao tá»‘c. Äá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y, tÃ´i cáº§n tÃ¬m hiá»ƒu cÃ¡c quy Ä‘á»‹nh liÃªn quan Ä‘áº¿n tá»‘c Ä‘á»™ tá»‘i Ä‘a trÃªn Ä‘Æ°á»ng cao tá»‘c trong luáº­t giao thÃ´ng Viá»‡t Nam. VÄƒn báº£n phÃ¡p luáº­t khÃ´ng chá»©a thÃ´ng tin cá»¥ thá»ƒ vá» tá»‘c Ä‘á»™ tá»‘i Ä‘a, tuy nhiÃªn, theo Luáº­t Giao thÃ´ng Ä‘Æ°á»n...\n\nğŸ“Š Dataset Statistics:\nğŸ“ Train samples: 1802\nğŸ“ Val samples: 213\nğŸ“ Sample text length: 331 tokens\nğŸ“ Estimated max tokens needed: 331\n","output_type":"stream"}],"execution_count":15},{"id":"5001bd9b","cell_type":"markdown","source":"## ğŸ“ Training Configuration - Optimized for GRPO Synthetic Data\n\n### Settings cho model Ä‘Ã£ fine-tune + synthetic data:\n- **Epochs**: 1-2 (model Ä‘Ã£ cÃ³ base knowledge)\n- **Learning rate**: 5e-5 Ä‘áº¿n 1e-4 (tháº¥p hÆ¡n)\n- **Batch size**: Nhá» hÆ¡n do sequence dÃ i hÆ¡n\n- **More evaluation**: Monitor overfitting carefully","metadata":{}},{"id":"a49be28c","cell_type":"code","source":"# Training arguments optimized for GRPO synthetic data\ntraining_args = TrainingArguments(\n    # Output & Logging\n    output_dir=\"./outputs-grpo-synthetic\",\n    run_name=\"llama3.2-3b-grpo-synthetic-v1\",\n    \n    # Training dynamics - Conservative for already fine-tuned model\n    num_train_epochs=2,  # Start with 1 epoch, can increase if needed\n    per_device_train_batch_size=4,  # Reduced due to longer sequences\n    gradient_accumulation_steps=4,  # Increased to maintain effective batch size = 16\n    \n    # Optimization - Lower LR for already fine-tuned model\n    optim=\"adamw_8bit\",  # 8-bit AdamW for memory efficiency\n    learning_rate=2e-4,  # Lower LR than fresh model (was 2e-4)\n    weight_decay=0.01,\n    warmup_ratio=0.05,  # Shorter warmup (5% instead of 10%)\n    lr_scheduler_type=\"cosine\",  # Cosine annealing\n    \n    # Performance\n    fp16=not torch.cuda.is_bf16_supported(),  # Use FP16 for T4\n    bf16=torch.cuda.is_bf16_supported(),  # Use BF16 if supported\n    \n    # Logging & Saving - More frequent for careful monitoring\n    logging_steps=5,  # Very frequent logging for synthetic data\n    logging_strategy=\"steps\",\n    logging_first_step=True,\n    save_strategy=\"steps\",\n    save_steps=25,  # Save very frequently to avoid overfitting\n    save_total_limit=3,\n    \n    # Evaluation - Very frequent to catch overfitting early\n    eval_strategy=\"steps\",\n    eval_steps=25,  # Frequent evaluation\n    eval_accumulation_steps=1,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    \n    # Early stopping to prevent overfitting on synthetic data\n    # early_stopping_patience=3,\n    \n    # WandB integration\n    report_to=\"wandb\",\n    logging_nan_inf_filter=True,\n    include_inputs_for_metrics=False,\n    \n    # Progress bar\n    disable_tqdm=False,\n    log_level=\"info\",\n    dataloader_num_workers=2,\n)\n\nprint(\"âœ… Training arguments configured for GRPO synthetic data\")\nprint(f\"ğŸ’¾ Per device batch size: {training_args.per_device_train_batch_size}\")\nprint(f\"ğŸ“Š Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\nprint(f\"ğŸ“š Learning rate: {training_args.learning_rate} (reduced for fine-tuned model)\")\nprint(f\"ğŸ“Š Epochs: {training_args.num_train_epochs} (conservative approach)\")\nprint(f\"ğŸ• Total training steps: {len(train_dataset) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps) * training_args.num_train_epochs}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T03:57:01.105348Z","iopub.execute_input":"2025-12-02T03:57:01.106026Z","iopub.status.idle":"2025-12-02T03:57:01.144790Z","shell.execute_reply.started":"2025-12-02T03:57:01.105999Z","shell.execute_reply":"2025-12-02T03:57:01.144137Z"}},"outputs":[{"name":"stdout","text":"âœ… Training arguments configured for GRPO synthetic data\nğŸ’¾ Per device batch size: 4\nğŸ“Š Effective batch size: 16\nğŸ“š Learning rate: 0.0002 (reduced for fine-tuned model)\nğŸ“Š Epochs: 2 (conservative approach)\nğŸ• Total training steps: 224\n","output_type":"stream"}],"execution_count":16},{"id":"ea386905","cell_type":"code","source":"# Initialize trainer\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n    dataset_num_proc=2,\n    packing=False,  # Keep False for structured GRPO format\n    args=training_args,\n)\n\nprint(\"âœ… SFT Trainer initialized for GRPO synthetic data\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T03:57:07.841077Z","iopub.execute_input":"2025-12-02T03:57:07.841360Z","iopub.status.idle":"2025-12-02T03:57:17.670599Z","shell.execute_reply.started":"2025-12-02T03:57:07.841337Z","shell.execute_reply":"2025-12-02T03:57:17.669810Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=8):   0%|          | 0/1802 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1a27f0367004b96a6ae4fc4789d052a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=8):   0%|          | 0/213 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfa6343b1a6543b7ad95c1df14895c8c"}},"metadata":{}},{"name":"stderr","text":"Using auto half precision backend\n","output_type":"stream"},{"name":"stdout","text":"âœ… SFT Trainer initialized for GRPO synthetic data\n","output_type":"stream"}],"execution_count":17},{"id":"c6230ac6","cell_type":"markdown","source":"## ğŸš€ Start Training!\n\n**Estimated time**: ~30-60 min for 1 epoch (shorter due to pre-trained model)  \n**Memory usage**: ~15-16GB VRAM (longer sequences)  \n**Watch for**: Overfitting (eval loss increasing while train loss decreasing)","metadata":{}},{"id":"f7317cd7","cell_type":"code","source":"# Show GPU stats before training\ngpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"ğŸ–¥ï¸ GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"ğŸ’¾ {start_gpu_memory} GB of memory reserved.\")\nprint(f\"ğŸ¯ Training GRPO model with synthetic structured data...\")\n\n# Start training\nprint(\"\\nğŸš€ Starting GRPO synthetic data training...\\n\")\ntrainer_stats = trainer.train()\n\n# Show final stats\nused_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nused_memory_for_lora = round(used_memory - start_gpu_memory, 3)\nused_percentage = round(used_memory / max_memory * 100, 3)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"âœ… GRPO SYNTHETIC DATA TRAINING COMPLETED!\")\nprint(\"=\"*50)\nprint(f\"â±ï¸ Training time: {trainer_stats.metrics['train_runtime']:.2f} seconds\")\nprint(f\"ğŸ’¾ Peak reserved memory: {used_memory} GB\")\nprint(f\"ğŸ“Š Memory used for training: {used_memory_for_lora} GB\")\nprint(f\"ğŸ“ˆ Percentage of max memory: {used_percentage}%\")\nprint(f\"ğŸ¯ Final train loss: {trainer_stats.metrics['train_loss']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T03:57:22.484628Z","iopub.execute_input":"2025-12-02T03:57:22.485394Z","iopub.status.idle":"2025-12-02T04:36:57.435771Z","shell.execute_reply.started":"2025-12-02T03:57:22.485362Z","shell.execute_reply":"2025-12-02T04:36:57.435005Z"}},"outputs":[{"name":"stdout","text":"ğŸ–¥ï¸ GPU = Tesla T4. Max memory = 14.741 GB.\nğŸ’¾ 3.072 GB of memory reserved.\nğŸ¯ Training GRPO model with synthetic structured data...\n\nğŸš€ Starting GRPO synthetic data training...\n\n","output_type":"stream"},{"name":"stderr","text":"The following columns in the Training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\nskipped Embedding(128256, 3072, padding_idx=128004): 375.75M params\nskipped: 375.75M params\n==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 1,802 | Num Epochs = 2 | Total steps = 114\nO^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32\n \"-____-\"     Trainable parameters = 48,627,712 of 3,261,377,536 (1.49% trained)\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [114/114 39:01, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>0.710300</td>\n      <td>0.703001</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.670900</td>\n      <td>0.642131</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.589700</td>\n      <td>0.616110</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.584800</td>\n      <td>0.604359</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the Evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 213\n  Batch size = 8\nUnsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\nUsing gradient accumulation will be very slightly less accurate.\nRead more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\nSaving model checkpoint to ./outputs-grpo-synthetic/checkpoint-25\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mikeethanh--vietnamese-legal-llama3.2-3b-merged-sft-v1/snapshots/2e53eb44a6fae3e8d7c3d7760f2b9163383c18c5/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"dtype\": \"float16\",\n  \"eos_token_id\": 128009,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pad_token_id\": 128004,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"transformers_version\": \"4.56.2\",\n  \"unsloth_fixed\": true,\n  \"unsloth_version\": \"2025.11.4\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nThe following columns in the Evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 213\n  Batch size = 8\nSaving model checkpoint to ./outputs-grpo-synthetic/checkpoint-50\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mikeethanh--vietnamese-legal-llama3.2-3b-merged-sft-v1/snapshots/2e53eb44a6fae3e8d7c3d7760f2b9163383c18c5/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"dtype\": \"float16\",\n  \"eos_token_id\": 128009,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pad_token_id\": 128004,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"transformers_version\": \"4.56.2\",\n  \"unsloth_fixed\": true,\n  \"unsloth_version\": \"2025.11.4\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nThe following columns in the Evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 213\n  Batch size = 8\nSaving model checkpoint to ./outputs-grpo-synthetic/checkpoint-75\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mikeethanh--vietnamese-legal-llama3.2-3b-merged-sft-v1/snapshots/2e53eb44a6fae3e8d7c3d7760f2b9163383c18c5/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"dtype\": \"float16\",\n  \"eos_token_id\": 128009,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pad_token_id\": 128004,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"transformers_version\": \"4.56.2\",\n  \"unsloth_fixed\": true,\n  \"unsloth_version\": \"2025.11.4\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nThe following columns in the Evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 213\n  Batch size = 8\nSaving model checkpoint to ./outputs-grpo-synthetic/checkpoint-100\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mikeethanh--vietnamese-legal-llama3.2-3b-merged-sft-v1/snapshots/2e53eb44a6fae3e8d7c3d7760f2b9163383c18c5/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"dtype\": \"float16\",\n  \"eos_token_id\": 128009,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pad_token_id\": 128004,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"transformers_version\": \"4.56.2\",\n  \"unsloth_fixed\": true,\n  \"unsloth_version\": \"2025.11.4\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nDeleting older checkpoint [outputs-grpo-synthetic/checkpoint-25] due to args.save_total_limit\nSaving model checkpoint to ./outputs-grpo-synthetic/checkpoint-114\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mikeethanh--vietnamese-legal-llama3.2-3b-merged-sft-v1/snapshots/2e53eb44a6fae3e8d7c3d7760f2b9163383c18c5/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"dtype\": \"float16\",\n  \"eos_token_id\": 128009,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pad_token_id\": 128004,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"transformers_version\": \"4.56.2\",\n  \"unsloth_fixed\": true,\n  \"unsloth_version\": \"2025.11.4\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nDeleting older checkpoint [outputs-grpo-synthetic/checkpoint-50] due to args.save_total_limit\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from ./outputs-grpo-synthetic/checkpoint-100 (score: 0.6043591499328613).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–ˆâ–„â–‚â–</td></tr><tr><td>eval/runtime</td><td>â–ˆâ–â–ƒâ–‚</td></tr><tr><td>eval/samples_per_second</td><td>â–â–ˆâ–†â–‡</td></tr><tr><td>eval/steps_per_second</td><td>â–â–ˆâ–‡â–‡</td></tr><tr><td>train/epoch</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–†â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–‡â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.60436</td></tr><tr><td>eval/runtime</td><td>56.1082</td></tr><tr><td>eval/samples_per_second</td><td>3.796</td></tr><tr><td>eval/steps_per_second</td><td>0.481</td></tr><tr><td>total_flos</td><td>2.537355139880141e+16</td></tr><tr><td>train/epoch</td><td>2</td></tr><tr><td>train/global_step</td><td>114</td></tr><tr><td>train/grad_norm</td><td>0.2101</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.572</td></tr><tr><td>train_loss</td><td>0.69664</td></tr><tr><td>train_runtime</td><td>2371.586</td></tr><tr><td>train_samples_per_second</td><td>1.52</td></tr><tr><td>train_steps_per_second</td><td>0.048</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">llama3.2-3b-grpo-synthetic-sft-v1</strong> at: <a href='https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-grpo/runs/5s0e4g20' target=\"_blank\">https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-grpo/runs/5s0e4g20</a><br> View project at: <a href='https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-grpo' target=\"_blank\">https://wandb.ai/mikeethanh04-student/vietnamese-legal-ai-grpo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20251202_034504-5s0e4g20/logs</code>"},"metadata":{}},{"name":"stdout","text":"\n==================================================\nâœ… GRPO SYNTHETIC DATA TRAINING COMPLETED!\n==================================================\nâ±ï¸ Training time: 2371.59 seconds\nğŸ’¾ Peak reserved memory: 6.746 GB\nğŸ“Š Memory used for training: 3.674 GB\nğŸ“ˆ Percentage of max memory: 45.764%\nğŸ¯ Final train loss: 0.6966\n","output_type":"stream"}],"execution_count":18},{"id":"59518c97","cell_type":"markdown","source":"## ğŸ“Š Evaluation","metadata":{}},{"id":"469ffa60","cell_type":"code","source":"# Evaluate on validation set\nprint(\"ğŸ“Š Evaluating on validation set...\\n\")\neval_results = trainer.evaluate()\n\nprint(\"=\"*50)\nprint(\"VALIDATION RESULTS - GRPO SYNTHETIC\")\nprint(\"=\"*50)\nfor key, value in eval_results.items():\n    print(f\"{key}: {value:.4f}\" if isinstance(value, float) else f\"{key}: {value}\")\n\n# Log to WandB\nwandb.log({\n    \"final_eval_loss\": eval_results['eval_loss'],\n    \"model_type\": \"grpo_synthetic_sft\"\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T04:37:26.132430Z","iopub.execute_input":"2025-12-02T04:37:26.133191Z","iopub.status.idle":"2025-12-02T04:38:24.245864Z","shell.execute_reply.started":"2025-12-02T04:37:26.133159Z","shell.execute_reply":"2025-12-02T04:38:24.244638Z"}},"outputs":[{"name":"stderr","text":"The following columns in the Evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 213\n  Batch size = 8\n","output_type":"stream"},{"name":"stdout","text":"ğŸ“Š Evaluating on validation set...\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [27/27 00:56]\n    </div>\n    "},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/4116084778.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ğŸ“Š Evaluating on validation set...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4491\u001b[0m         )\n\u001b[1;32m   4492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4493\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(self, logs, start_time)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(self, logs, start_time)\u001b[0m\n\u001b[1;32m   3788\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3789\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3790\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mon_log\u001b[0;34m(self, args, state, control, logs)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_log\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_prediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mcall_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             result = getattr(callback, event)(\n\u001b[0m\u001b[1;32m    557\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/integrations/integration_utils.py\u001b[0m in \u001b[0;36mon_log\u001b[0;34m(self, args, state, control, model, logs, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m             \u001b[0mnon_scalar_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msingle_value_scalars\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0mnon_scalar_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewrite_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_scalar_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnon_scalar_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train/global_step\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/preinit.py\u001b[0m in \u001b[0;36mpreinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m ) -> Callable:\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"You must call wandb.init() before {name}()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"],"ename":"Error","evalue":"You must call wandb.init() before wandb.log()","output_type":"error"}],"execution_count":19},{"id":"545a590a","cell_type":"markdown","source":"## ğŸ§ª Inference Testing - GRPO Format Validation","metadata":{}},{"id":"7b904fa0","cell_type":"code","source":"# Enable native 2x faster inference\nFastLanguageModel.for_inference(model)\n\n# GRPO format markers for validation\nreasoning_start = \"<start_working_out>\"\nreasoning_end = \"<end_working_out>\"\nsolution_start = \"<SOLUTION>\"\nsolution_end = \"</SOLUTION>\"\n\ndef test_grpo_model(user_message, max_new_tokens=512):\n    \"\"\"Test model with GRPO system prompt\"\"\"\n    \n    # GRPO system prompt\n    system_prompt = f\"\"\"Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn vá» luáº­t giao thÃ´ng Viá»‡t Nam. Khi tráº£ lá»i cÃ¢u há»i, hÃ£y:\n1. Suy nghÄ© vÃ  phÃ¢n tÃ­ch cÃ¢u há»i trong pháº§n {reasoning_start} {reasoning_end}\n2. ÄÆ°a ra cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c trong pháº§n {solution_start}{solution_end}\n\nCÃ¢u tráº£ lá»i cáº§n dá»±a trÃªn quy Ä‘á»‹nh phÃ¡p luáº­t hiá»‡n hÃ nh vÃ  pháº£i rÃµ rÃ ng, dá»… hiá»ƒu.\"\"\"\n    \n    messages = [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": user_message}\n    ]\n    \n    # Apply chat template\n    prompt = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n    \n    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n    \n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=max_new_tokens,\n        temperature=0.7,\n        top_p=0.9,\n        do_sample=True,\n        use_cache=True,\n        pad_token_id=tokenizer.eos_token_id\n    )\n    \n    response = tokenizer.batch_decode(outputs)[0]\n    # Extract only the response part\n    if \"<|start_header_id|>assistant<|end_header_id|>\" in response:\n        response = response.split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1]\n        response = response.split(\"<|eot_id|>\")[0].strip()\n    \n    return response\n\ndef validate_grpo_format(response):\n    \"\"\"Validate if response follows GRPO format\"\"\"\n    has_reasoning = reasoning_start in response and reasoning_end in response\n    has_solution = solution_start in response and solution_end in response\n    \n    return {\n        \"has_reasoning\": has_reasoning,\n        \"has_solution\": has_solution,\n        \"proper_format\": has_reasoning and has_solution\n    }\n\n# Test questions\ntest_questions = [\n    \"Má»©c pháº¡t cho viá»‡c vÆ°á»£t Ä‘Ã¨n Ä‘á» Ä‘á»‘i vá»›i xe mÃ¡y lÃ  bao nhiÃªu?\",\n    \"Äiá»u kiá»‡n Ä‘á»ƒ Ä‘Æ°á»£c cáº¥p báº±ng lÃ¡i xe Ã´ tÃ´ háº¡ng B1 lÃ  gÃ¬?\",\n    \"HÃ nh vi nÃ o bá»‹ cáº¥m khi tham gia giao thÃ´ng Ä‘Æ°á»ng bá»™?\"\n]\n\nprint(\"ğŸ§ª Testing GRPO model with structured format validation...\\n\")\nprint(\"=\"*80)\n\nformat_validation_results = []\n\nfor i, question in enumerate(test_questions, 1):\n    print(f\"\\n{'='*80}\")\n    print(f\"TEST QUESTION #{i}\")\n    print(f\"{'='*80}\")\n    print(f\"\\nâ“ Question: {question}\")\n    \n    # Generate response\n    response = test_grpo_model(question)\n    print(f\"\\nğŸ¤– Model Response:\\n{response}\")\n    \n    # Validate format\n    validation = validate_grpo_format(response)\n    format_validation_results.append(validation)\n    \n    print(f\"\\nğŸ“Š Format Validation:\")\n    print(f\"   Has reasoning section: {validation['has_reasoning']} âœ…\" if validation['has_reasoning'] else f\"   Has reasoning section: {validation['has_reasoning']} âŒ\")\n    print(f\"   Has solution section: {validation['has_solution']} âœ…\" if validation['has_solution'] else f\"   Has solution section: {validation['has_solution']} âŒ\")\n    print(f\"   Proper GRPO format: {validation['proper_format']} âœ…\" if validation['proper_format'] else f\"   Proper GRPO format: {validation['proper_format']} âŒ\")\n    print(f\"\\n{'='*80}\")\n\n# Summary of format validation\nproper_format_count = sum(1 for r in format_validation_results if r['proper_format'])\nprint(f\"\\nğŸ“Š GRPO FORMAT VALIDATION SUMMARY:\")\nprint(f\"   Proper format: {proper_format_count}/{len(test_questions)} ({proper_format_count/len(test_questions)*100:.1f}%)\")\n\nif proper_format_count == len(test_questions):\n    print(\"ğŸ‰ Excellent! Model consistently follows GRPO format\")\nelif proper_format_count >= len(test_questions) * 0.7:\n    print(\"âœ… Good! Model mostly follows GRPO format\")\nelse:\n    print(\"âš ï¸ Warning: Model needs more training on GRPO format\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T04:38:28.932633Z","iopub.execute_input":"2025-12-02T04:38:28.933522Z","iopub.status.idle":"2025-12-02T04:39:24.207203Z","shell.execute_reply.started":"2025-12-02T04:38:28.933487Z","shell.execute_reply":"2025-12-02T04:39:24.206583Z"}},"outputs":[{"name":"stdout","text":"ğŸ§ª Testing GRPO model with structured format validation...\n\n================================================================================\n\n================================================================================\nTEST QUESTION #1\n================================================================================\n\nâ“ Question: Má»©c pháº¡t cho viá»‡c vÆ°á»£t Ä‘Ã¨n Ä‘á» Ä‘á»‘i vá»›i xe mÃ¡y lÃ  bao nhiÃªu?\n\nğŸ¤– Model Response:\n<start_working_out>\nCÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng lÃ  vá» má»©c pháº¡t Ä‘á»‘i vá»›i viá»‡c vÆ°á»£t Ä‘Ã¨n Ä‘á» cá»§a xe mÃ¡y theo quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t Viá»‡t Nam. Äá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y, tÃ´i sáº½ tÃ¬m kiáº¿m thÃ´ng tin trong vÄƒn báº£n phÃ¡p luáº­t Ä‘Ã£ cung cáº¥p, Ä‘áº·c biá»‡t lÃ  cÃ¡c Ä‘iá»u khoáº£n liÃªn quan Ä‘áº¿n viá»‡c vi pháº¡m giao thÃ´ng, nhÆ° hÃ nh vi vÆ°á»£t Ä‘Ã¨n Ä‘á». \n\nTrong vÄƒn báº£n phÃ¡p luáº­t, cÃ³ má»™t Ä‘iá»ƒm c khoáº£n 3 Äiá»u 3 quy Ä‘á»‹nh ráº±ng \"xe mÃ´-tÃ´, xe gáº¯n mÃ¡y\" khÃ´ng Ä‘Æ°á»£c phÃ©p vÆ°á»£t Ä‘Ã¨n Ä‘á». Tuy nhiÃªn, vÄƒn báº£n khÃ´ng nÃªu rÃµ má»©c pháº¡t cá»¥ thá»ƒ cho hÃ nh vi nÃ y. ThÃ´ng thÆ°á»ng, má»©c pháº¡t Ä‘á»‘i vá»›i hÃ nh vi vÆ°á»£t Ä‘Ã¨n Ä‘á» lÃ  tá»« 1.000.000 Ä‘áº¿n 2.000.000 Ä‘á»“ng, tÃ¹y thuá»™c vÃ o má»©c Ä‘á»™ vi pháº¡m vÃ  kháº£ nÄƒng cá»§a ngÆ°á»i lÃ¡i xe. \n\nVÃ¬ váº­y, cáº§n tham kháº£o thÃªm cÃ¡c quy Ä‘á»‹nh khÃ¡c hoáº·c cÃ¡c vÄƒn báº£n phÃ¡p luáº­t khÃ¡c Ä‘á»ƒ cÃ³ thÃ´ng tin cá»¥ thá»ƒ hÆ¡n vá» má»©c pháº¡t nÃ y.\n<end_working_out>\n\n<SOLUTION>Má»©c pháº¡t cho viá»‡c vÆ°á»£t Ä‘Ã¨n Ä‘á» Ä‘á»‘i vá»›i xe mÃ¡y khÃ´ng Ä‘Æ°á»£c quy Ä‘á»‹nh rÃµ rÃ ng trong vÄƒn báº£n phÃ¡p luáº­t Ä‘Ã£ cung cáº¥p. Tuy nhiÃªn, theo quy Ä‘á»‹nh chung, ngÆ°á»i lÃ¡i xe cÃ³ thá»ƒ bá»‹ pháº¡t tá»« 1.000.000 Ä‘áº¿n 2.000.000 Ä‘á»“ng tÃ¹y thuá»™c vÃ o má»©c Ä‘á»™ vi pháº¡m. Báº¡n nÃªn tham kháº£o thÃªm cÃ¡c quy Ä‘á»‹nh khÃ¡c Ä‘á»ƒ cÃ³ thÃ´ng tin chÃ­nh xÃ¡c hÆ¡n.</SOLUTION>\n\nğŸ“Š Format Validation:\n   Has reasoning section: True âœ…\n   Has solution section: True âœ…\n   Proper GRPO format: True âœ…\n\n================================================================================\n\n================================================================================\nTEST QUESTION #2\n================================================================================\n\nâ“ Question: Äiá»u kiá»‡n Ä‘á»ƒ Ä‘Æ°á»£c cáº¥p báº±ng lÃ¡i xe Ã´ tÃ´ háº¡ng B1 lÃ  gÃ¬?\n\nğŸ¤– Model Response:\n<start_working_out>\nCÃ¢u há»i yÃªu cáº§u thÃ´ng tin vá» Ä‘iá»u kiá»‡n Ä‘á»ƒ Ä‘Æ°á»£c cáº¥p báº±ng lÃ¡i xe Ã´ tÃ´ háº¡ng B1. NgÆ°á»i dÃ¹ng muá»‘n biáº¿t nhá»¯ng yÃªu cáº§u cá»¥ thá»ƒ mÃ  há» cáº§n Ä‘Ã¡p á»©ng Ä‘á»ƒ Ä‘Æ°á»£c cáº¥p giáº¥y phÃ©p lÃ¡i xe nÃ y. Trong vÄƒn báº£n phÃ¡p luáº­t Ä‘Ã£ cung cáº¥p, cÃ³ má»™t Ä‘iá»u khoáº£n liÃªn quan Ä‘áº¿n viá»‡c cáº¥p giáº¥y phÃ©p lÃ¡i xe Ã´ tÃ´, cá»¥ thá»ƒ lÃ  Äiá»u 56. Tuy nhiÃªn, vÄƒn báº£n khÃ´ng nÃªu rÃµ Ä‘iá»u kiá»‡n cá»¥ thá»ƒ cho tá»«ng háº¡ng giáº¥y phÃ©p lÃ¡i xe, nhÆ° váº­y cáº§n pháº£i lÃ m rÃµ thÃªm. ThÃ´ng thÆ°á»ng, Ä‘á»ƒ Ä‘Æ°á»£c cáº¥p báº±ng lÃ¡i xe háº¡ng B1, ngÆ°á»i lÃ¡i cáº§n cÃ³ Ä‘á»™ tuá»•i phÃ¹ há»£p, cÃ³ sá»©c khá»e vÃ  Ä‘áº¡t yÃªu cáº§u vá» thá»i gian lÃ¡i xe thá»±c hÃ nh. \n\nTÃ³m láº¡i, Ä‘iá»u kiá»‡n chÃ­nh bao gá»“m Ä‘á»™ tuá»•i, sá»©c khá»e vÃ  sá»‘ km lÃ¡i xe thá»±c hÃ nh theo quy Ä‘á»‹nh cá»§a cÆ¡ quan cÃ³ tháº©m quyá»n.\n<end_working_out>\n\n<SOLUTION>Äá»ƒ Ä‘Æ°á»£c cáº¥p báº±ng lÃ¡i xe Ã´ tÃ´ háº¡ng B1, báº¡n cáº§n Ä‘Ã¡p á»©ng cÃ¡c Ä‘iá»u kiá»‡n sau: 1) CÃ³ Ä‘á»™ tuá»•i phÃ¹ há»£p theo quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t, 2) CÃ³ sá»©c khá»e theo tiÃªu chuáº©n cá»§a Bá»™ trÆ°á»Ÿng Bá»™ Y táº¿, vÃ  3) Äá»§ sá»‘ km lÃ¡i xe thá»±c hÃ nh theo quy Ä‘á»‹nh cá»§a cÆ¡ quan cÃ³ tháº©m quyá»n. Báº¡n nÃªn tham kháº£o thÃªm cÃ¡c quy Ä‘á»‹nh chi tiáº¿t trong Luáº­t Giao thÃ´ng Ä‘Æ°á»ng bá»™ vÃ  quy Ä‘á»‹nh cá»§a Bá»™ trÆ°á»Ÿng Bá»™ Giao thÃ´ng váº­n táº£i vá» viá»‡c cáº¥p giáº¥y phÃ©p lÃ¡i xe.</SOLUTION>\n\nğŸ“Š Format Validation:\n   Has reasoning section: True âœ…\n   Has solution section: True âœ…\n   Proper GRPO format: True âœ…\n\n================================================================================\n\n================================================================================\nTEST QUESTION #3\n================================================================================\n\nâ“ Question: HÃ nh vi nÃ o bá»‹ cáº¥m khi tham gia giao thÃ´ng Ä‘Æ°á»ng bá»™?\n\nğŸ¤– Model Response:\n<start_working_out>\nCÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng yÃªu cáº§u thÃ´ng tin vá» cÃ¡c hÃ nh vi bá»‹ cáº¥m khi tham gia giao thÃ´ng Ä‘Æ°á»ng bá»™. Äá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y, tÃ´i sáº½ tÃ¬m kiáº¿m cÃ¡c Ä‘iá»u khoáº£n trong vÄƒn báº£n phÃ¡p luáº­t liÃªn quan Ä‘áº¿n giao thÃ´ng. \n\nTheo Äiá»u 3, khoáº£n 4 cá»§a vÄƒn báº£n, cÃ³ nÃªu rÃµ \"Äiá»u cáº¥m: - ÄÆ°a xe cÆ¡ giá»›i Ä‘i vÃ o Ä‘Æ°á»ng dÃ nh cho ngÆ°á»i Ä‘i bá»™, xe lÄƒn cá»§a ngÆ°á»i tÃ n táº­t, xe thÃ´ sÆ¡.\" Äiá»u nÃ y cÃ³ nghÄ©a lÃ  cÃ¡c hÃ nh vi nhÆ° chá»Ÿ hÃ ng cá»“ng ká»nh, chá»Ÿ sÃºc váº­t trÃªn xe cÆ¡ giá»›i, hay sá»­ dá»¥ng Ä‘iá»‡n thoáº¡i khi lÃ¡i xe cÅ©ng Ä‘á»u bá»‹ cáº¥m. \n\nNgoÃ i ra, cÃ¡c hÃ nh vi khÃ¡c nhÆ° Ä‘i xe dÃ n hÃ ng ngang, khÃ´ng nhÆ°á»ng Ä‘Æ°á»ng cho ngÆ°á»i Ä‘i bá»™, hay khÃ´ng tuÃ¢n thá»§ tÃ­n hiá»‡u giao thÃ´ng cÅ©ng Ä‘á»u bá»‹ cáº¥m theo cÃ¡c quy Ä‘á»‹nh khÃ¡c trong vÄƒn báº£n phÃ¡p luáº­t.\n\nTÃ³m láº¡i, cÃ¡c hÃ nh vi bá»‹ cáº¥m khi tham gia giao thÃ´ng Ä‘Æ°á»ng bá»™ bao gá»“m viá»‡c sá»­ dá»¥ng Ä‘iá»‡n thoáº¡i, chá»Ÿ hÃ ng cá»“ng ká»nh, vÃ  cÃ¡c hÃ nh vi vi pháº¡m khÃ¡c. \n<end_working_out>\n\n<SOLUTION>CÃ¡c hÃ nh vi bá»‹ cáº¥m khi tham gia giao thÃ´ng Ä‘Æ°á»ng bá»™ bao gá»“m: - ÄÆ°a xe cÆ¡ giá»›i Ä‘i vÃ o Ä‘Æ°á»ng dÃ nh cho ngÆ°á»i Ä‘i bá»™, xe lÄƒn cá»§a ngÆ°á»i tÃ n táº­t, xe thÃ´ sÆ¡; - Chá»Ÿ hÃ ng cá»“ng ká»nh; - ÄÆ°a xe cÆ¡ giá»›i Ä‘i dÃ n hÃ ng ngang; - Sá»­ dá»¥ng Ä‘iá»‡n thoáº¡i khi lÃ¡i xe; vÃ  cÃ¡c hÃ nh vi vi pháº¡m khÃ¡c theo quy Ä‘á»‹nh táº¡i Äiá»u 3, khoáº£n 4 cá»§a vÄƒn báº£n phÃ¡p luáº­t. </SOLUTION>\n\nğŸ“Š Format Validation:\n   Has reasoning section: True âœ…\n   Has solution section: True âœ…\n   Proper GRPO format: True âœ…\n\n================================================================================\n\nğŸ“Š GRPO FORMAT VALIDATION SUMMARY:\n   Proper format: 3/3 (100.0%)\nğŸ‰ Excellent! Model consistently follows GRPO format\n","output_type":"stream"}],"execution_count":20},{"id":"46afa2dd","cell_type":"markdown","source":"## ğŸ’¾ Save Model","metadata":{}},{"id":"af9f9461","cell_type":"code","source":"# Optional: Save merged model (full size ~6GB)\nmodel.save_pretrained_merged(\"grpo_synthetic_merged\", tokenizer, save_method=\"merged_16bit\")\nprint(\"âœ… GRPO synthetic merged model saved to: grpo_synthetic_merged/\")\nprint(\"ğŸ¯ This model now has: Base â†’ GRPO training â†’ Synthetic data SFT\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T04:39:24.208106Z","iopub.execute_input":"2025-12-02T04:39:24.208547Z","iopub.status.idle":"2025-12-02T04:40:16.699712Z","shell.execute_reply.started":"2025-12-02T04:39:24.208512Z","shell.execute_reply":"2025-12-02T04:40:16.698932Z"}},"outputs":[{"name":"stderr","text":"Configuration saved in grpo_synthetic_merged/config.json\n","output_type":"stream"},{"name":"stdout","text":"Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bb2ebe272d943d0b28647cbd1030ed2"}},"metadata":{}},{"name":"stdout","text":"Checking cache directory for required files...\n","output_type":"stream"},{"name":"stderr","text":"Unsloth: Copying 2 files from cache to `grpo_synthetic_merged`: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Successfully copied all 2 files from cache to `grpo_synthetic_merged`\nChecking cache directory for required files...\nCache check failed: tokenizer.model not found in local cache.\nNot all required files found in cache. Will proceed with downloading.\n","output_type":"stream"},{"name":"stderr","text":"Unsloth: Preparing safetensor model files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 21076.90it/s]\nUnsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:41<00:00, 20.81s/it]\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Merge process complete. Saved to `/kaggle/working/grpo_synthetic_merged`\nâœ… GRPO synthetic merged model saved to: grpo_synthetic_merged/\nğŸ¯ This model now has: Base â†’ GRPO training â†’ Synthetic data SFT\n","output_type":"stream"}],"execution_count":21},{"id":"aaf0930b","cell_type":"markdown","source":"## ğŸ“¤ Model Upload & Export","metadata":{}},{"id":"2cf0aa5f","cell_type":"code","source":"# Upload merged model to HuggingFace Hub (giáº£i phÃ¡p cho file lá»›n!)\n# BÆ°á»›c 1: Táº¡o HuggingFace account táº¡i https://huggingface.co/join\n# BÆ°á»›c 2: Táº¡o token táº¡i https://huggingface.co/settings/tokens (chá»n \"Write\" permission)\n# BÆ°á»›c 3: ThÃªm token vÃ o Kaggle Secrets vá»›i key \"HF_TOKEN\"\n\nimport os\n\nif os.path.exists(\"/kaggle/working\"):\n    print(\"ğŸš€ Uploading model to HuggingFace Hub...\")\n    print(\"=\"*70)\n    \n    try:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n        \n        from huggingface_hub import HfApi, login\n        \n        # Login to HuggingFace\n        login(token=hf_token)\n        print(\"âœ… Logged in to HuggingFace\")\n        \n        # Thay YOUR_USERNAME báº±ng username HuggingFace cá»§a báº¡n\n        YOUR_HF_USERNAME = \"mikeethanh\"  # âš ï¸ Sá»¬A DÃ’NG NÃ€Y!\n        repo_name = f\"{YOUR_HF_USERNAME}/vietnamese-legal-llama3.2-3b-merged-sft-v2\"\n        \n        print(f\"\\nğŸ“¤ Uploading to: {repo_name}\")\n        print(\"â³ Äang upload ~6GB, cÃ³ thá»ƒ máº¥t 10-15 phÃºt...\\n\")\n        \n        # Upload merged model\n        if os.path.exists(\"grpo_synthetic_merged\"):\n            from huggingface_hub import create_repo, upload_folder\n            \n            # Create repo (public)\n            try:\n                create_repo(repo_name, repo_type=\"model\", exist_ok=True)\n                print(f\"âœ… Repository created: https://huggingface.co/{repo_name}\")\n            except:\n                print(f\"â„¹ï¸ Repository already exists: https://huggingface.co/{repo_name}\")\n            \n            # Upload folder\n            upload_folder(\n                folder_path=\"grpo_synthetic_merged\",\n                repo_id=repo_name,\n                commit_message=\"Vietnamese Legal AI - Llama 3.2 3B Merged Model\",\n            )\n            \n            print(\"\\n\" + \"=\"*70)\n            print(\"âœ… UPLOAD THÃ€NH CÃ”NG!\")\n            print(\"=\"*70)\n            print(f\"\\nğŸ“¥ Download model vá» mÃ¡y báº±ng cÃ¡ch:\")\n            print(f\"   git clone https://huggingface.co/{repo_name}\")\n            print(f\"\\nğŸŒ Hoáº·c xem trÃªn web:\")\n            print(f\"   https://huggingface.co/{repo_name}\")\n            print(\"\\nğŸ’¡ Model Ä‘Ã£ public, ai cÅ©ng cÃ³ thá»ƒ download!\")\n        else:\n            print(\"âš ï¸ Folder 'vietnamese_legal_merged' not found!\")\n            \n    except Exception as e:\n        print(f\"âŒ Error: {e}\")\n        print(\"\\nğŸ“ HÆ°á»›ng dáº«n fix:\")\n        print(\"  1. Táº¡o account táº¡i: https://huggingface.co/join\")\n        print(\"  2. Táº¡o token táº¡i: https://huggingface.co/settings/tokens\")\n        print(\"  3. Kaggle: Add-ons â†’ Secrets â†’ Add 'HF_TOKEN'\")\n        print(\"  4. Sá»­a YOUR_USERNAME trong code\")\n        \nelse:\n    print(\"â„¹ï¸ This cell only works on Kaggle\")\n    print(\"ğŸ’¡ For local, use: model.push_to_hub() directly\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T04:42:36.134096Z","iopub.execute_input":"2025-12-02T04:42:36.134862Z","iopub.status.idle":"2025-12-02T04:43:45.000256Z","shell.execute_reply.started":"2025-12-02T04:42:36.134833Z","shell.execute_reply":"2025-12-02T04:43:44.999424Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Uploading model to HuggingFace Hub...\n======================================================================\nâœ… Logged in to HuggingFace\n\nğŸ“¤ Uploading to: mikeethanh/vietnamese-legal-llama3.2-3b-merged-sft-v2\nâ³ Äang upload ~6GB, cÃ³ thá»ƒ máº¥t 10-15 phÃºt...\n\nâœ… Repository created: https://huggingface.co/mikeethanh/vietnamese-legal-llama3.2-3b-merged-sft-v2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28b552a950de47148b5361cffc755bb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2265f70aac62407888d77da223b93d90"}},"metadata":{}},{"name":"stdout","text":"\n======================================================================\nâœ… UPLOAD THÃ€NH CÃ”NG!\n======================================================================\n\nğŸ“¥ Download model vá» mÃ¡y báº±ng cÃ¡ch:\n   git clone https://huggingface.co/mikeethanh/vietnamese-legal-llama3.2-3b-merged-sft-v2\n\nğŸŒ Hoáº·c xem trÃªn web:\n   https://huggingface.co/mikeethanh/vietnamese-legal-llama3.2-3b-merged-sft-v2\n\nğŸ’¡ Model Ä‘Ã£ public, ai cÅ©ng cÃ³ thá»ƒ download!\n","output_type":"stream"}],"execution_count":25},{"id":"2877158b","cell_type":"markdown","source":"## ğŸ“Š Quantization Export","metadata":{}},{"id":"ad7eba56","cell_type":"code","source":"# Export to GGUF for deployment\nquantization_methods = [\n    \"q8_0\",    # Fast inference, good quality\n    \"q4_k_m\",  # Smaller size, good balance\n]\n\nfor method in quantization_methods:\n    print(f\"\\nğŸ“¦ Exporting GRPO synthetic model to {method.upper()}...\")\n    model.save_pretrained_gguf(\n        \"grpo_synthetic_model\",\n        tokenizer,\n        quantization_method=method,\n    )\n    print(f\"âœ… Exported: grpo_synthetic_model-{method.upper()}.gguf\")\n\nprint(\"\\nâœ… All GGUF exports completed!\")\nprint(\"ğŸš€ Ready for deployment with Ollama or llama.cpp\")","metadata":{},"outputs":[],"execution_count":null},{"id":"801b7b3b","cell_type":"markdown","source":"## ğŸ‰ Training Summary & Cleanup","metadata":{}},{"id":"aaa02820","cell_type":"code","source":"# Finish WandB run\nwandb.finish()\n\n# Clear GPU memory\ndel model\ndel trainer\ngc.collect()\ntorch.cuda.empty_cache()\n\nprint(\"âœ… GRPO Synthetic Data Training completed successfully!\")\nprint(\"\\nğŸ“Š FINAL SUMMARY:\")\nprint(\"=\"*60)\nprint(f\"ğŸ¤– Base Model: mikeethanh/vietnamese-legal-llama3.2-3b-merged-grpo\")\nprint(f\"ğŸ“Š Training samples: {len(train_data):,} (synthetic GRPO format)\")\nprint(f\"ğŸ“Š Validation samples: {len(val_data):,}\")\nprint(f\"ğŸ“Š Test samples: {len(test_data):,}\")\nprint(f\"â±ï¸ Training time: ~{trainer_stats.metrics['train_runtime']/60:.1f} minutes\")\nprint(f\"ğŸ¯ Final eval loss: {eval_results['eval_loss']:.4f}\")\n\nprint(\"\\nğŸ“‚ SAVED OUTPUTS:\")\nprint(\"  âœ… LoRA adapters: grpo_synthetic_lora/\")\nprint(\"  âœ… Merged model: grpo_synthetic_merged/\")\nprint(\"  âœ… GGUF models: grpo_synthetic_model-*.gguf\")\n\nprint(\"\\nğŸ¯ MODEL EVOLUTION COMPLETE:\")\nprint(\"  1ï¸âƒ£ Base: Llama-3.2-3B-Instruct\")\nprint(\"  2ï¸âƒ£ GRPO: Reinforcement learning vá»›i reward functions\")\nprint(\"  3ï¸âƒ£ SFT: Synthetic data vá»›i structured reasoning format\")\n\nprint(\"\\nğŸš€ NEXT STEPS:\")\nprint(\"  1. Test model on real user queries\")\nprint(\"  2. Validate GRPO format consistency\")\nprint(\"  3. Deploy and collect feedback\")\nprint(\"  4. Iterate with more synthetic data if needed\")\n\nprint(\"\\nğŸ‰ Training pipeline complete! Model ready for deployment.\")","metadata":{},"outputs":[],"execution_count":null}]}